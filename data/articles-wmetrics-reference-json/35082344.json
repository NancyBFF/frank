{"BERTS2S": "google has pledged $ 1bn ( \u00a3800m ) to research and research into artificial intelligence ( ai ).", "BERTS2S_lines": ["google has pledged $ 1bn ( \u00a3800m ) to research and research into artificial intelligence ( ai )."], "TConvS2S": "ai weiwei, the founder of ai giant ai weiwei, has launched a $ 1m (\u00c2 # venture) research project.", "TConvS2S_lines": ["ai weiwei, the founder of ai giant ai weiwei, has launched a $ 1m (\u00c2 # venture) research project."], "Gold": "prominent tech executives have pledged $ 1bn (# 659m) for openai, a non-profit venture that aims to develop artificial intelligence (ai) to benefit humanity.", "Gold_lines": ["prominent tech executives have pledged $ 1bn (# 659m) for openai, a non-profit venture that aims to develop artificial intelligence", "(ai) to benefit humanity."], "PtGen": "open ai weiwei has unveiled a $ [UNK] (\u00c2 # [UNK]) venture prize for the spirit of liberty.", "PtGen_lines": ["open ai weiwei has unveiled a $ [UNK] (\u00c2 # [UNK])", "venture prize for the spirit of liberty."], "TranS2S": "one of the world\\'s biggest physicists has warned that artificial intelligence could be used in humans.", "TranS2S_lines": ["one of the world\\'s biggest physicists has warned that artificial intelligence could be used in humans."], "article": "The venture's backers include Tesla Motors and SpaceX CEO Elon Musk, Paypal co-founder Peter Thiel, Indian tech giant Infosys and Amazon Web Services.Open AI says it expects its research - free from financial obligations - to focus on a \"positive human impact\".Scientists have warned that advances in AI could ultimately threaten humanity.Mr Musk recently told students at the Massachusetts Institute of Technology (MIT) that AI was humanity's \"biggest existential threat\".Last year, British theoretical physicist Stephen Hawking told the BBC AI could potentially \"re-design itself at an ever increasing rate\", superseding humans by outpacing biological evolution.However, other experts have argued that the risk of AI posing any threat to humans remains remote.A statement on OpenAI's website said the venture aims \"to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return\".\"It's hard to fathom how much human-level AI could benefit society, and it's equally hard to imagine how much it could damage society if built or used incorrectly.\"The statement said AI \"should be an extension of individual human wills and, in the spirit of liberty, as broadly and evenly distributed as is possible safely\".It said only a tiny fraction of the $1bn pledged would be spent in the next few years.", "article_lines": ["The venture's backers include Tesla Motors and SpaceX CEO Elon Musk, Paypal co-founder Peter Thiel, Indian tech giant Infosys and Amazon Web Services.", "Open AI says it expects its research - free from financial obligations - to focus on a \"positive human impact\".", "Scientists have warned that advances in AI could ultimately threaten humanity.", "Mr Musk recently told students at the Massachusetts Institute of Technology (MIT) that AI was humanity's \"biggest existential threat\".", "Last year, British theoretical physicist Stephen Hawking told the BBC AI could potentially \"re-design itself at an ever increasing rate\", superseding humans by outpacing biological evolution.", "However, other experts have argued that the risk of AI posing any threat to humans remains remote.", "A statement on OpenAI's website said the venture aims \"to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return\".", "\"It's hard to fathom how much human-level AI could benefit society, and it's equally hard to imagine how much it could damage society if built or used incorrectly.", "\"The", "statement said AI \"should be an extension of individual human wills and, in the spirit of liberty, as broadly and evenly distributed as is possible safely\".", "It said only a tiny fraction of the $1bn pledged would be spent in the next few years."], "entity_counter": {"The venture's backers": 1, "Tesla Motors": 1, "SpaceX CEO Elon Musk": 1, "Paypal co-founder Peter Thiel": 1, "Indian tech giant": 1, "Infosys": 1, "Amazon Web Services": 1, "Open AI": 2, "financial obligations": 1, "Scientists": 1, "advances": 1, "AI": 4, "humanity": 2, "Mr Musk": 1, "students": 1, "the Massachusetts Institute": 1, "Technology": 1, "MIT": 1, "humanity's \"biggest existential threat\"": 1, "British theoretical physicist Stephen Hawking": 1, "an ever increasing rate": 1, "humans": 2, "biological evolution": 1, "other experts": 1, "the risk": 1, "any threat": 1, "A statement": 1, "OpenAI's website": 1, "the venture": 1, "digital intelligence": 1, "the way": 1, "a need": 1, "financial return\"": 1, "human-level AI": 1, "society": 2, "statement": 1, "an extension": 1, "individual human wills": 1, "the spirit": 1, "liberty": 1, "only a tiny fraction": 1, "the $1bn": 1}, "negative_entity": "lake", "url": "http://web.archive.org/web/20170330090026/http://www.bbc.co.uk/news/technology-35082344", "hash": "35082344", "traps": [["F5", "institute website 's liberty be hawking 's ever the humans is tech to."], ["F6", "open ai says it expects my research - free from financial obligations - to focus on a \"positive human impact\"."], ["F0", "the venture's backers include tesla motors and spacex ceo elon musk, paypal co-founder peter thiel, indian tech giant infosys and amazon web services."], ["F5", "evolution humanity humanity of could if thiel."], ["F1", "scientists have warned that advances in ai could not ultimately threaten humanity ."], ["F6", "open ai says it expects your research - free from financial obligations - to focus on a \"positive human impact\"."]], "model_names": ["BERTS2S_lines", "TConvS2S_lines", "Gold_lines", "PtGen_lines", "TranS2S_lines"], "BERTS2S_rouge": {"rouge_1_recall": 0.26087, "rouge_1_recall_cb": 0.26087, "rouge_1_recall_ce": 0.26087, "rouge_1_precision": 0.46154, "rouge_1_precision_cb": 0.46154, "rouge_1_precision_ce": 0.46154, "rouge_1_f_score": 0.33333, "rouge_1_f_score_cb": 0.33333, "rouge_1_f_score_ce": 0.33333, "rouge_2_recall": 0.13636, "rouge_2_recall_cb": 0.13636, "rouge_2_recall_ce": 0.13636, "rouge_2_precision": 0.25, "rouge_2_precision_cb": 0.25, "rouge_2_precision_ce": 0.25, "rouge_2_f_score": 0.17647, "rouge_2_f_score_cb": 0.17647, "rouge_2_f_score_ce": 0.17647, "rouge_3_recall": 0.04762, "rouge_3_recall_cb": 0.04762, "rouge_3_recall_ce": 0.04762, "rouge_3_precision": 0.09091, "rouge_3_precision_cb": 0.09091, "rouge_3_precision_ce": 0.09091, "rouge_3_f_score": 0.0625, "rouge_3_f_score_cb": 0.0625, "rouge_3_f_score_ce": 0.0625, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.26087, "rouge_l_recall_cb": 0.26087, "rouge_l_recall_ce": 0.26087, "rouge_l_precision": 0.46154, "rouge_l_precision_cb": 0.46154, "rouge_l_precision_ce": 0.46154, "rouge_l_f_score": 0.33333, "rouge_l_f_score_cb": 0.33333, "rouge_l_f_score_ce": 0.33333, "rouge_w_1.2_recall": 0.11802, "rouge_w_1.2_recall_cb": 0.11802, "rouge_w_1.2_recall_ce": 0.11802, "rouge_w_1.2_precision": 0.39092, "rouge_w_1.2_precision_cb": 0.39092, "rouge_w_1.2_precision_ce": 0.39092, "rouge_w_1.2_f_score": 0.1813, "rouge_w_1.2_f_score_cb": 0.1813, "rouge_w_1.2_f_score_ce": 0.1813, "rouge_s*_recall": 0.05929, "rouge_s*_recall_cb": 0.05929, "rouge_s*_recall_ce": 0.05929, "rouge_s*_precision": 0.19231, "rouge_s*_precision_cb": 0.19231, "rouge_s*_precision_ce": 0.19231, "rouge_s*_f_score": 0.09064, "rouge_s*_f_score_cb": 0.09064, "rouge_s*_f_score_ce": 0.09064, "rouge_su*_recall": 0.07273, "rouge_su*_recall_cb": 0.07273, "rouge_su*_recall_ce": 0.07273, "rouge_su*_precision": 0.22222, "rouge_su*_precision_cb": 0.22222, "rouge_su*_precision_ce": 0.22222, "rouge_su*_f_score": 0.10959, "rouge_su*_f_score_cb": 0.10959, "rouge_su*_f_score_ce": 0.10959}, "BERTS2S_bleu": 19.770070731005916, "BERTS2S_meteor": 0.182679303471511, "TConvS2S_rouge": {"rouge_1_recall": 0.13043, "rouge_1_recall_cb": 0.13043, "rouge_1_recall_ce": 0.13043, "rouge_1_precision": 0.1875, "rouge_1_precision_cb": 0.1875, "rouge_1_precision_ce": 0.1875, "rouge_1_f_score": 0.15384, "rouge_1_f_score_cb": 0.15384, "rouge_1_f_score_ce": 0.15384, "rouge_2_recall": 0.0, "rouge_2_recall_cb": 0.0, "rouge_2_recall_ce": 0.0, "rouge_2_precision": 0.0, "rouge_2_precision_cb": 0.0, "rouge_2_precision_ce": 0.0, "rouge_2_f_score": 0.0, "rouge_2_f_score_cb": 0.0, "rouge_2_f_score_ce": 0.0, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.08696, "rouge_l_recall_cb": 0.08696, "rouge_l_recall_ce": 0.08696, "rouge_l_precision": 0.125, "rouge_l_precision_cb": 0.125, "rouge_l_precision_ce": 0.125, "rouge_l_f_score": 0.10257, "rouge_l_f_score_cb": 0.10257, "rouge_l_f_score_ce": 0.10257, "rouge_w_1.2_recall": 0.04138, "rouge_w_1.2_recall_cb": 0.04138, "rouge_w_1.2_recall_ce": 0.04138, "rouge_w_1.2_precision": 0.11136, "rouge_w_1.2_precision_cb": 0.11136, "rouge_w_1.2_precision_ce": 0.11136, "rouge_w_1.2_f_score": 0.06034, "rouge_w_1.2_f_score_cb": 0.06034, "rouge_w_1.2_f_score_ce": 0.06034, "rouge_s*_recall": 0.00395, "rouge_s*_recall_cb": 0.00395, "rouge_s*_recall_ce": 0.00395, "rouge_s*_precision": 0.00833, "rouge_s*_precision_cb": 0.00833, "rouge_s*_precision_ce": 0.00833, "rouge_s*_f_score": 0.00536, "rouge_s*_f_score_cb": 0.00536, "rouge_s*_f_score_ce": 0.00536, "rouge_su*_recall": 0.01455, "rouge_su*_recall_cb": 0.01455, "rouge_su*_recall_ce": 0.01455, "rouge_su*_precision": 0.02963, "rouge_su*_precision_cb": 0.02963, "rouge_su*_precision_ce": 0.02963, "rouge_su*_f_score": 0.01952, "rouge_su*_f_score_cb": 0.01952, "rouge_su*_f_score_ce": 0.01952}, "TConvS2S_bleu": 2.1222510155108316, "TConvS2S_meteor": 0.09266409266409267, "PtGen_rouge": {"rouge_1_recall": 0.17391, "rouge_1_recall_cb": 0.17391, "rouge_1_recall_ce": 0.17391, "rouge_1_precision": 0.26667, "rouge_1_precision_cb": 0.26667, "rouge_1_precision_ce": 0.26667, "rouge_1_f_score": 0.21053, "rouge_1_f_score_cb": 0.21053, "rouge_1_f_score_ce": 0.21053, "rouge_2_recall": 0.0, "rouge_2_recall_cb": 0.0, "rouge_2_recall_ce": 0.0, "rouge_2_precision": 0.0, "rouge_2_precision_cb": 0.0, "rouge_2_precision_ce": 0.0, "rouge_2_f_score": 0.0, "rouge_2_f_score_cb": 0.0, "rouge_2_f_score_ce": 0.0, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.08696, "rouge_l_recall_cb": 0.08696, "rouge_l_recall_ce": 0.08696, "rouge_l_precision": 0.13333, "rouge_l_precision_cb": 0.13333, "rouge_l_precision_ce": 0.13333, "rouge_l_f_score": 0.10526, "rouge_l_f_score_cb": 0.10526, "rouge_l_f_score_ce": 0.10526, "rouge_w_1.2_recall": 0.04138, "rouge_w_1.2_recall_cb": 0.04138, "rouge_w_1.2_recall_ce": 0.04138, "rouge_w_1.2_precision": 0.11879, "rouge_w_1.2_precision_cb": 0.11879, "rouge_w_1.2_precision_ce": 0.11879, "rouge_w_1.2_f_score": 0.06138, "rouge_w_1.2_f_score_cb": 0.06138, "rouge_w_1.2_f_score_ce": 0.06138, "rouge_s*_recall": 0.00395, "rouge_s*_recall_cb": 0.00395, "rouge_s*_recall_ce": 0.00395, "rouge_s*_precision": 0.00952, "rouge_s*_precision_cb": 0.00952, "rouge_s*_precision_ce": 0.00952, "rouge_s*_f_score": 0.00558, "rouge_s*_f_score_cb": 0.00558, "rouge_s*_f_score_ce": 0.00558, "rouge_su*_recall": 0.01818, "rouge_su*_recall_cb": 0.01818, "rouge_su*_recall_ce": 0.01818, "rouge_su*_precision": 0.04202, "rouge_su*_precision_cb": 0.04202, "rouge_su*_precision_ce": 0.04202, "rouge_su*_f_score": 0.02538, "rouge_su*_f_score_cb": 0.02538, "rouge_su*_f_score_ce": 0.02538}, "PtGen_bleu": 2.135901868558124, "PtGen_meteor": 0.09160305343511452, "TranS2S_rouge": {"rouge_1_recall": 0.17391, "rouge_1_recall_cb": 0.17391, "rouge_1_recall_ce": 0.17391, "rouge_1_precision": 0.23529, "rouge_1_precision_cb": 0.23529, "rouge_1_precision_ce": 0.23529, "rouge_1_f_score": 0.2, "rouge_1_f_score_cb": 0.2, "rouge_1_f_score_ce": 0.2, "rouge_2_recall": 0.04545, "rouge_2_recall_cb": 0.04545, "rouge_2_recall_ce": 0.04545, "rouge_2_precision": 0.0625, "rouge_2_precision_cb": 0.0625, "rouge_2_precision_ce": 0.0625, "rouge_2_f_score": 0.05263, "rouge_2_f_score_cb": 0.05263, "rouge_2_f_score_ce": 0.05263, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.17391, "rouge_l_recall_cb": 0.17391, "rouge_l_recall_ce": 0.17391, "rouge_l_precision": 0.23529, "rouge_l_precision_cb": 0.23529, "rouge_l_precision_ce": 0.23529, "rouge_l_f_score": 0.2, "rouge_l_f_score_cb": 0.2, "rouge_l_f_score_ce": 0.2, "rouge_w_1.2_recall": 0.07827, "rouge_w_1.2_recall_cb": 0.07827, "rouge_w_1.2_recall_ce": 0.07827, "rouge_w_1.2_precision": 0.19825, "rouge_w_1.2_precision_cb": 0.19825, "rouge_w_1.2_precision_ce": 0.19825, "rouge_w_1.2_f_score": 0.11223, "rouge_w_1.2_f_score_cb": 0.11223, "rouge_w_1.2_f_score_ce": 0.11223, "rouge_s*_recall": 0.02372, "rouge_s*_recall_cb": 0.02372, "rouge_s*_recall_ce": 0.02372, "rouge_s*_precision": 0.04412, "rouge_s*_precision_cb": 0.04412, "rouge_s*_precision_ce": 0.04412, "rouge_s*_f_score": 0.03085, "rouge_s*_f_score_cb": 0.03085, "rouge_s*_f_score_ce": 0.03085, "rouge_su*_recall": 0.03273, "rouge_su*_recall_cb": 0.03273, "rouge_su*_recall_ce": 0.03273, "rouge_su*_precision": 0.05921, "rouge_su*_precision_cb": 0.05921, "rouge_su*_precision_ce": 0.05921, "rouge_su*_f_score": 0.04216, "rouge_su*_f_score_cb": 0.04216, "rouge_su*_f_score_ce": 0.04216}, "TranS2S_bleu": 2.6987341279976564, "TranS2S_meteor": 0.08699393596095376}