{"BERTS2S": "american apparel has filed a defamation case against the board of board members, accusing him of harassing staff and harassment of the company.", "BERTS2S_lines": ["american apparel has filed a defamation case against the board of board members, accusing him of harassing staff and harassment of the company."], "TConvS2S": "american apparel boss charney charney has been ordered to pay $ funds (\u00c2 # charney) to the company, the company has said.", "TConvS2S_lines": ["american apparel boss charney charney has been ordered to pay $ funds (\u00c2 # charney) to the company, the company has said."], "Gold": "the retailer american apparel has detailed sexist and racist misconduct claims against former boss dov charney in a court filing.", "Gold_lines": ["the retailer american apparel has detailed sexist and racist misconduct claims against former boss dov charney in a court filing."], "PtGen": "the former chief executive of the san francisco court, charney charney, has been cleared by a court in california.", "PtGen_lines": ["the former chief executive of the san francisco court, charney charney, has been cleared by a court in california."], "TranS2S": "american apparel\\'s business has filed a lawsuit against its former chief executive keith charney.", "TranS2S_lines": ["american apparel\\'s business has filed a lawsuit against its former chief executive keith charney."], "article": "Mr Charney, who also founded the company, was ousted last year because of the employee complaints and amid accusations of misuse of company funds.In the San Francisco court filing, the board said it did not expect him ever to return to the firm.Mr Charney's lawyer said many of the statements made were false.\"The company has engaged in an invasion of Mr Charney's privacy in a shameful attempt to extort him and gain leverage over him,\" said his lawyer Keith Fink.The court filing documents evidence of illicit emails written to female employees by the former chief executive, as well as racially derogatory taunts.They come in response to Mr Charney's defamation lawsuit against the company and its chair.Mr Charney \"repeatedly engaged in conduct that violated the company's sexual harassment and anti-discrimination policy,\" the company's papers say.\"Given this set of facts... it would be hard to find any board of any company... that would be willing to hire Mr Charney as its CEO, executive, or employee. The risk to the company and its shareholders would just be too great,\" the board adds.Earlier this month, American Apparel was granted a restraining order preventing him from making any negative statements in the press about the company and from trying to get board members removed.", "article_lines": ["Mr Charney, who also founded the company, was ousted last year because of the employee complaints and amid accusations of misuse of company funds.", "In the San Francisco court filing, the board said it did not expect him ever to return to the firm.", "Mr Charney's lawyer said many of the statements made were false.", "\"The", "company has engaged in an invasion of Mr Charney's privacy in a shameful attempt to extort him and gain leverage over him,\" said his lawyer Keith Fink.", "The court filing documents evidence of illicit emails written to female employees by the former chief executive, as well as racially derogatory taunts.", "They come in response to Mr Charney's defamation lawsuit against the company and its chair.", "Mr Charney \"repeatedly engaged in conduct that violated the company's sexual harassment and anti-discrimination policy,\" the company's papers say.", "\"Given this set of facts...", "it would be hard to find any board of any company...", "that would be willing to hire Mr Charney as its CEO, executive, or employee.", "The risk to the company and its shareholders would just be too great,\" the board adds.", "Earlier this month, American Apparel was granted a restraining order preventing him from making any negative statements in the press about the company and from trying to get board members removed."], "entity_counter": {"Mr Charney": 3, "the company": 2, "the employee complaints": 1, "accusations": 1, "misuse": 1, "company funds": 1, "the San Francisco court filing": 1, "the board": 2, "the firm": 1, "Mr Charney's lawyer": 1, "the statements": 1, "company": 3, "an invasion": 1, "Mr Charney's privacy": 1, "a shameful attempt": 1, "leverage": 1, "his lawyer": 1, "Keith Fink": 1, "The court": 1, "documents": 1, "evidence": 1, "illicit emails": 1, "female employees": 1, "the former chief executive": 1, "racially derogatory taunts": 1, "response": 1, "Mr Charney's defamation lawsuit": 1, "its chair": 1, "conduct": 1, "the company's sexual harassment": 1, "anti-discrimination policy": 1, "the company's papers": 1, "this set": 1, "facts": 1, "any board": 1, "any company": 1, "its CEO": 1, "executive": 1, "employee": 1, "The risk": 1, "its shareholders": 1, "American Apparel": 1, "a restraining order": 1, "any negative statements": 1, "the press": 1, "board members": 1}, "negative_entity": "John", "url": "http://web.archive.org/web/20151007204229/http://www.bbc.co.uk/news/business-33261110", "hash": "33261110", "traps": [["F0", "mr charney, who also founded the company, was ousted last year because of the employee complaints and amid accusations of misuse of company funds."], ["F5", "leverage chair risk invasion in."], ["F6", "they come in response to mr charney's defamation lawsuit against the company and my chair."], ["F6", "that would be willing to hire mr charney as my ceo, executive, or employee."], ["F0", "mr charney, who also founded the company, was ousted last year because of the employee complaints and amid accusations of misuse of company funds."], ["F6", "the risk to the company and her shareholders would just be too great,\" the board adds."]], "model_names": ["BERTS2S_lines", "TConvS2S_lines", "Gold_lines", "PtGen_lines", "TranS2S_lines"], "BERTS2S_rouge": {"rouge_1_recall": 0.4, "rouge_1_recall_cb": 0.4, "rouge_1_recall_ce": 0.4, "rouge_1_precision": 0.34783, "rouge_1_precision_cb": 0.34783, "rouge_1_precision_ce": 0.34783, "rouge_1_f_score": 0.3721, "rouge_1_f_score_cb": 0.3721, "rouge_1_f_score_ce": 0.3721, "rouge_2_recall": 0.10526, "rouge_2_recall_cb": 0.10526, "rouge_2_recall_ce": 0.10526, "rouge_2_precision": 0.09091, "rouge_2_precision_cb": 0.09091, "rouge_2_precision_ce": 0.09091, "rouge_2_f_score": 0.09756, "rouge_2_f_score_cb": 0.09756, "rouge_2_f_score_ce": 0.09756, "rouge_3_recall": 0.05556, "rouge_3_recall_cb": 0.05556, "rouge_3_recall_ce": 0.05556, "rouge_3_precision": 0.04762, "rouge_3_precision_cb": 0.04762, "rouge_3_precision_ce": 0.04762, "rouge_3_f_score": 0.05128, "rouge_3_f_score_cb": 0.05128, "rouge_3_f_score_ce": 0.05128, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.2, "rouge_l_recall_cb": 0.2, "rouge_l_recall_ce": 0.2, "rouge_l_precision": 0.17391, "rouge_l_precision_cb": 0.17391, "rouge_l_precision_ce": 0.17391, "rouge_l_f_score": 0.18604, "rouge_l_f_score_cb": 0.18604, "rouge_l_f_score_ce": 0.18604, "rouge_w_1.2_recall": 0.10039, "rouge_w_1.2_recall_cb": 0.10039, "rouge_w_1.2_recall_ce": 0.10039, "rouge_w_1.2_precision": 0.15893, "rouge_w_1.2_precision_cb": 0.15893, "rouge_w_1.2_precision_ce": 0.15893, "rouge_w_1.2_f_score": 0.12305, "rouge_w_1.2_f_score_cb": 0.12305, "rouge_w_1.2_f_score_ce": 0.12305, "rouge_s*_recall": 0.08421, "rouge_s*_recall_cb": 0.08421, "rouge_s*_recall_ce": 0.08421, "rouge_s*_precision": 0.06324, "rouge_s*_precision_cb": 0.06324, "rouge_s*_precision_ce": 0.06324, "rouge_s*_f_score": 0.07223, "rouge_s*_f_score_cb": 0.07223, "rouge_s*_f_score_ce": 0.07223, "rouge_su*_recall": 0.11005, "rouge_su*_recall_cb": 0.11005, "rouge_su*_recall_ce": 0.11005, "rouge_su*_precision": 0.08364, "rouge_su*_precision_cb": 0.08364, "rouge_su*_precision_ce": 0.08364, "rouge_su*_f_score": 0.09504, "rouge_su*_f_score_cb": 0.09504, "rouge_su*_f_score_ce": 0.09504}, "BERTS2S_bleu": 7.164684238257436, "BERTS2S_meteor": 0.11762916482796172, "TConvS2S_rouge": {"rouge_1_recall": 0.3, "rouge_1_recall_cb": 0.3, "rouge_1_recall_ce": 0.3, "rouge_1_precision": 0.31579, "rouge_1_precision_cb": 0.31579, "rouge_1_precision_ce": 0.31579, "rouge_1_f_score": 0.30769, "rouge_1_f_score_cb": 0.30769, "rouge_1_f_score_ce": 0.30769, "rouge_2_recall": 0.05263, "rouge_2_recall_cb": 0.05263, "rouge_2_recall_ce": 0.05263, "rouge_2_precision": 0.05556, "rouge_2_precision_cb": 0.05556, "rouge_2_precision_ce": 0.05556, "rouge_2_f_score": 0.05406, "rouge_2_f_score_cb": 0.05406, "rouge_2_f_score_ce": 0.05406, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.2, "rouge_l_recall_cb": 0.2, "rouge_l_recall_ce": 0.2, "rouge_l_precision": 0.21053, "rouge_l_precision_cb": 0.21053, "rouge_l_precision_ce": 0.21053, "rouge_l_f_score": 0.20513, "rouge_l_f_score_cb": 0.20513, "rouge_l_f_score_ce": 0.20513, "rouge_w_1.2_recall": 0.10039, "rouge_w_1.2_recall_cb": 0.10039, "rouge_w_1.2_recall_ce": 0.10039, "rouge_w_1.2_precision": 0.19239, "rouge_w_1.2_precision_cb": 0.19239, "rouge_w_1.2_precision_ce": 0.19239, "rouge_w_1.2_f_score": 0.13194, "rouge_w_1.2_f_score_cb": 0.13194, "rouge_w_1.2_f_score_ce": 0.13194, "rouge_s*_recall": 0.05263, "rouge_s*_recall_cb": 0.05263, "rouge_s*_recall_ce": 0.05263, "rouge_s*_precision": 0.05848, "rouge_s*_precision_cb": 0.05848, "rouge_s*_precision_ce": 0.05848, "rouge_s*_f_score": 0.0554, "rouge_s*_f_score_cb": 0.0554, "rouge_s*_f_score_ce": 0.0554, "rouge_su*_recall": 0.07656, "rouge_su*_recall_cb": 0.07656, "rouge_su*_recall_ce": 0.07656, "rouge_su*_precision": 0.08466, "rouge_su*_precision_cb": 0.08466, "rouge_su*_precision_ce": 0.08466, "rouge_su*_f_score": 0.08041, "rouge_su*_f_score_cb": 0.08041, "rouge_su*_f_score_ce": 0.08041}, "TConvS2S_bleu": 3.951744928978941, "TConvS2S_meteor": 0.12264394144945824, "PtGen_rouge": {"rouge_1_recall": 0.35, "rouge_1_recall_cb": 0.35, "rouge_1_recall_ce": 0.35, "rouge_1_precision": 0.36842, "rouge_1_precision_cb": 0.36842, "rouge_1_precision_ce": 0.36842, "rouge_1_f_score": 0.35897, "rouge_1_f_score_cb": 0.35897, "rouge_1_f_score_ce": 0.35897, "rouge_2_recall": 0.05263, "rouge_2_recall_cb": 0.05263, "rouge_2_recall_ce": 0.05263, "rouge_2_precision": 0.05556, "rouge_2_precision_cb": 0.05556, "rouge_2_precision_ce": 0.05556, "rouge_2_f_score": 0.05406, "rouge_2_f_score_cb": 0.05406, "rouge_2_f_score_ce": 0.05406, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.25, "rouge_l_recall_cb": 0.25, "rouge_l_recall_ce": 0.25, "rouge_l_precision": 0.26316, "rouge_l_precision_cb": 0.26316, "rouge_l_precision_ce": 0.26316, "rouge_l_f_score": 0.25641, "rouge_l_f_score_cb": 0.25641, "rouge_l_f_score_ce": 0.25641, "rouge_w_1.2_recall": 0.11019, "rouge_w_1.2_recall_cb": 0.11019, "rouge_w_1.2_recall_ce": 0.11019, "rouge_w_1.2_precision": 0.21117, "rouge_w_1.2_precision_cb": 0.21117, "rouge_w_1.2_precision_ce": 0.21117, "rouge_w_1.2_f_score": 0.14481, "rouge_w_1.2_f_score_cb": 0.14481, "rouge_w_1.2_f_score_ce": 0.14481, "rouge_s*_recall": 0.08947, "rouge_s*_recall_cb": 0.08947, "rouge_s*_recall_ce": 0.08947, "rouge_s*_precision": 0.09942, "rouge_s*_precision_cb": 0.09942, "rouge_s*_precision_ce": 0.09942, "rouge_s*_f_score": 0.09418, "rouge_s*_f_score_cb": 0.09418, "rouge_s*_f_score_ce": 0.09418, "rouge_su*_recall": 0.11483, "rouge_su*_recall_cb": 0.11483, "rouge_su*_recall_ce": 0.11483, "rouge_su*_precision": 0.12698, "rouge_su*_precision_cb": 0.12698, "rouge_su*_precision_ce": 0.12698, "rouge_su*_f_score": 0.1206, "rouge_su*_f_score_cb": 0.1206, "rouge_su*_f_score_ce": 0.1206}, "PtGen_bleu": 4.885326644211927, "PtGen_meteor": 0.14870332277459883, "TranS2S_rouge": {"rouge_1_recall": 0.4, "rouge_1_recall_cb": 0.4, "rouge_1_recall_ce": 0.4, "rouge_1_precision": 0.53333, "rouge_1_precision_cb": 0.53333, "rouge_1_precision_ce": 0.53333, "rouge_1_f_score": 0.45714, "rouge_1_f_score_cb": 0.45714, "rouge_1_f_score_ce": 0.45714, "rouge_2_recall": 0.05263, "rouge_2_recall_cb": 0.05263, "rouge_2_recall_ce": 0.05263, "rouge_2_precision": 0.07143, "rouge_2_precision_cb": 0.07143, "rouge_2_precision_ce": 0.07143, "rouge_2_f_score": 0.06061, "rouge_2_f_score_cb": 0.06061, "rouge_2_f_score_ce": 0.06061, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.3, "rouge_l_recall_cb": 0.3, "rouge_l_recall_ce": 0.3, "rouge_l_precision": 0.4, "rouge_l_precision_cb": 0.4, "rouge_l_precision_ce": 0.4, "rouge_l_f_score": 0.34286, "rouge_l_f_score_cb": 0.34286, "rouge_l_f_score_ce": 0.34286, "rouge_w_1.2_recall": 0.13957, "rouge_w_1.2_recall_cb": 0.13957, "rouge_w_1.2_recall_ce": 0.13957, "rouge_w_1.2_precision": 0.3388, "rouge_w_1.2_precision_cb": 0.3388, "rouge_w_1.2_precision_ce": 0.3388, "rouge_w_1.2_f_score": 0.1977, "rouge_w_1.2_f_score_cb": 0.1977, "rouge_w_1.2_f_score_ce": 0.1977, "rouge_s*_recall": 0.11053, "rouge_s*_recall_cb": 0.11053, "rouge_s*_recall_ce": 0.11053, "rouge_s*_precision": 0.2, "rouge_s*_precision_cb": 0.2, "rouge_s*_precision_ce": 0.2, "rouge_s*_f_score": 0.14238, "rouge_s*_f_score_cb": 0.14238, "rouge_s*_f_score_ce": 0.14238, "rouge_su*_recall": 0.12919, "rouge_su*_recall_cb": 0.12919, "rouge_su*_recall_ce": 0.12919, "rouge_su*_precision": 0.22689, "rouge_su*_precision_cb": 0.22689, "rouge_su*_precision_ce": 0.22689, "rouge_su*_f_score": 0.16464, "rouge_su*_f_score_cb": 0.16464, "rouge_su*_f_score_ce": 0.16464}, "TranS2S_bleu": 5.112296259271881, "TranS2S_meteor": 0.17643529168543773}