{"BERTS2S": "italy\\'s lower house of parliament has passed a controversial parliamentary reform of the country\\'s electoral system.", "BERTS2S_lines": ["italy\\'s lower house of parliament has passed a controversial parliamentary reform of the country\\'s electoral system."], "TConvS2S": "italy\\'s lower house of parliament has voted to end the process of reducing the country\\'s power system.", "TConvS2S_lines": ["italy\\'s lower house of parliament has voted to end the process of reducing the country\\'s power system."], "Gold": "the italian parliament has approved a long-debated and extensive electoral reform that aims to give the country more political stability.", "Gold_lines": ["the italian parliament has approved a long-debated and extensive electoral reform that aims to give the country more political stability."], "PtGen": "voters in italy have voted overwhelmingly to elect a new president in the wake of the italian election system.", "PtGen_lines": ["voters in italy have voted overwhelmingly to elect a new president in the wake of the italian election system."], "TranS2S": "italian prime minister matteo renzi has won the latest stage in a vote in italy\\'s parliament.", "TranS2S_lines": ["italian prime minister matteo renzi has won the latest stage in a vote in italy\\'s parliament."], "article": "Share this withEmailFacebookMessengerMessengerTwitterPinterestWhatsAppLinkedinCopy this linkThe measure guarantees a majority of seats to the party that wins the most votes in an election.It is a key element of a package of reforms promised by Italian Prime Minister Matteo Renzi.The law seeks to end Italy's post-war era of revolving governments, political horse-trading and unstable coalitions.The lower house of parliament gave final approval to the bill by 334 votes to 61.The proportional election system awards 340 out of 630 seats to any party that wins more than 40% of the national vote.If no party reaches that threshold, there is a second-round run-off between the two parties with the most votes.The electoral reform is expected to come into force next year.After the vote, Mr Renzi said: \"Commitment achieved, promise respected. Italy needs people who don't always say no.\"Critics have accused the 40-year-old former mayor of Florence who became prime minster last year of trying to consolidate his grip on power.They complain that the law awards too much power to single parties, gives party bosses too much scope to select candidates, and denies voters the chance to directly choose representatives. Opposition parties boycotted Monday's vote.Renato Brunetta, parliamentary head of centre-right opposition party Forza Italia, said afterwards that it was \"a very ugly day for our country's democracy\".Mr Renzi wants to further transform the Italian system by abolishing the Senate and replacing it with a non-elected body with lesser powers.Currently, legislation is often held up because identical versions of bills have to be approved by both houses.", "article_lines": ["Share this withEmailFacebookMessengerMessengerTwitterPinterestWhatsAppLinkedinCopy", "this linkThe measure guarantees a majority of seats to the party that wins the most votes in an election.", "It is a key element of a package of reforms promised by Italian Prime Minister Matteo Renzi.", "The law seeks to end Italy's post-war era of revolving governments, political horse-trading and unstable coalitions.", "The lower house of parliament gave final approval to the bill by 334 votes to 61.The proportional election system awards 340 out of 630 seats to any party that wins more than 40% of the national vote.", "If no party reaches that threshold, there is a second-round run-off between the two parties with the most votes.", "The electoral reform is expected to come into force next year.", "After the vote, Mr Renzi said: \"Commitment achieved, promise respected.", "Italy needs people who don't always say no.", "\"Critics have accused the 40-year-old former mayor of Florence who became prime minster last year of trying to consolidate his grip on power.", "They complain that the law awards too much power to single parties, gives party bosses too much scope to select candidates, and denies voters the chance to directly choose representatives.", "Opposition parties boycotted Monday's vote.", "Renato Brunetta, parliamentary head of centre-right opposition party Forza Italia, said afterwards that it was \"a very ugly day for our country's democracy\".", "Mr Renzi wants to further transform the Italian system by abolishing the Senate and replacing it with a non-elected body with lesser powers.", "Currently, legislation is often held up because identical versions of bills have to be approved by both houses."], "entity_counter": {"this withEmailFacebookMessengerMessengerTwitterPinterestWhatsAppLinkedinCopy": 1, "this linkThe measure": 1, "a majority": 1, "seats": 1, "the party": 1, "the most votes": 2, "an election": 1, "a key element": 1, "a package": 1, "reforms": 1, "Italian Prime Minister Matteo Renzi": 3, "The law": 2, "Italy's post-war era": 1, "revolving governments": 1, "political horse-trading and unstable coalitions": 1, "The lower house": 1, "parliament": 1, "final approval": 1, "the bill": 1, "334 votes": 1, "630 seats": 1, "any party": 1, "the national vote": 1, "no party": 1, "that threshold": 1, "a second-round run-off": 1, "the two parties": 1, "The electoral reform": 1, "force": 1, "the vote": 1, "Commitment": 1, "promise": 1, "Italy": 1, "people": 1, "the 40-year-old former mayor": 1, "Florence": 1, "prime minster": 1, "his grip": 1, "power": 1, "too much power": 1, "single parties": 1, "party bosses": 1, "too much scope": 1, "candidates": 1, "voters": 1, "the chance": 1, "representatives": 1, "Opposition parties": 1, "Monday's vote": 1, "Renato Brunetta": 1, "parliamentary head": 1, "centre-right opposition party Forza Italia": 1, "a very ugly day": 1, "our country's democracy\"": 1, "the Italian system": 1, "the Senate": 1, "a non-elected body": 1, "lesser powers": 1, "legislation": 1, "identical versions": 1, "bills": 1, "both houses": 1}, "negative_entity": "lake", "url": "http://web.archive.org/web/20170113010704/http://www.bbc.co.uk/news/world-europe-32584708", "hash": "32584708", "traps": [["F1", "italy needs people who do always say no ."], ["F5", "much italian became party key there most promise that country 40-year if by said have."], ["F4", "he accepted he had struck mrs blackburn but denies causing serious injury by dangerous driving."], ["F1", "the electoral reform is not expected to come into force next year ."], ["F4", "the boy is from northern ireland, but his family do not want him to be named to protect his identity."], ["F1", "the electoral reform is not expected to come into force next year ."]], "model_names": ["BERTS2S_lines", "TConvS2S_lines", "Gold_lines", "PtGen_lines", "TranS2S_lines"], "BERTS2S_rouge": {"rouge_1_recall": 0.33333, "rouge_1_recall_cb": 0.33333, "rouge_1_recall_ce": 0.33333, "rouge_1_precision": 0.38889, "rouge_1_precision_cb": 0.38889, "rouge_1_precision_ce": 0.38889, "rouge_1_f_score": 0.35897, "rouge_1_f_score_cb": 0.35897, "rouge_1_f_score_ce": 0.35897, "rouge_2_recall": 0.1, "rouge_2_recall_cb": 0.1, "rouge_2_recall_ce": 0.1, "rouge_2_precision": 0.11765, "rouge_2_precision_cb": 0.11765, "rouge_2_precision_ce": 0.11765, "rouge_2_f_score": 0.10811, "rouge_2_f_score_cb": 0.10811, "rouge_2_f_score_ce": 0.10811, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.28571, "rouge_l_recall_cb": 0.28571, "rouge_l_recall_ce": 0.28571, "rouge_l_precision": 0.33333, "rouge_l_precision_cb": 0.33333, "rouge_l_precision_ce": 0.33333, "rouge_l_f_score": 0.30769, "rouge_l_f_score_cb": 0.30769, "rouge_l_f_score_ce": 0.30769, "rouge_w_1.2_recall": 0.12474, "rouge_w_1.2_recall_cb": 0.12474, "rouge_w_1.2_recall_ce": 0.12474, "rouge_w_1.2_precision": 0.26754, "rouge_w_1.2_precision_cb": 0.26754, "rouge_w_1.2_precision_ce": 0.26754, "rouge_w_1.2_f_score": 0.17015, "rouge_w_1.2_f_score_cb": 0.17015, "rouge_w_1.2_f_score_ce": 0.17015, "rouge_s*_recall": 0.09048, "rouge_s*_recall_cb": 0.09048, "rouge_s*_recall_ce": 0.09048, "rouge_s*_precision": 0.12418, "rouge_s*_precision_cb": 0.12418, "rouge_s*_precision_ce": 0.12418, "rouge_s*_f_score": 0.10468, "rouge_s*_f_score_cb": 0.10468, "rouge_s*_f_score_ce": 0.10468, "rouge_su*_recall": 0.11304, "rouge_su*_recall_cb": 0.11304, "rouge_su*_recall_ce": 0.11304, "rouge_su*_precision": 0.15294, "rouge_su*_precision_cb": 0.15294, "rouge_su*_precision_ce": 0.15294, "rouge_su*_f_score": 0.13, "rouge_su*_f_score_cb": 0.13, "rouge_su*_f_score_ce": 0.13}, "BERTS2S_bleu": 6.108557268562174, "BERTS2S_meteor": 0.18970643469706544, "TConvS2S_rouge": {"rouge_1_recall": 0.28571, "rouge_1_recall_cb": 0.28571, "rouge_1_recall_ce": 0.28571, "rouge_1_precision": 0.31579, "rouge_1_precision_cb": 0.31579, "rouge_1_precision_ce": 0.31579, "rouge_1_f_score": 0.3, "rouge_1_f_score_cb": 0.3, "rouge_1_f_score_ce": 0.3, "rouge_2_recall": 0.1, "rouge_2_recall_cb": 0.1, "rouge_2_recall_ce": 0.1, "rouge_2_precision": 0.11111, "rouge_2_precision_cb": 0.11111, "rouge_2_precision_ce": 0.11111, "rouge_2_f_score": 0.10526, "rouge_2_f_score_cb": 0.10526, "rouge_2_f_score_ce": 0.10526, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.2381, "rouge_l_recall_cb": 0.2381, "rouge_l_recall_ce": 0.2381, "rouge_l_precision": 0.26316, "rouge_l_precision_cb": 0.26316, "rouge_l_precision_ce": 0.26316, "rouge_l_f_score": 0.25, "rouge_l_f_score_cb": 0.25, "rouge_l_f_score_ce": 0.25, "rouge_w_1.2_recall": 0.10877, "rouge_w_1.2_recall_cb": 0.10877, "rouge_w_1.2_recall_ce": 0.10877, "rouge_w_1.2_precision": 0.221, "rouge_w_1.2_precision_cb": 0.221, "rouge_w_1.2_precision_ce": 0.221, "rouge_w_1.2_f_score": 0.14579, "rouge_w_1.2_f_score_cb": 0.14579, "rouge_w_1.2_f_score_ce": 0.14579, "rouge_s*_recall": 0.05714, "rouge_s*_recall_cb": 0.05714, "rouge_s*_recall_ce": 0.05714, "rouge_s*_precision": 0.07018, "rouge_s*_precision_cb": 0.07018, "rouge_s*_precision_ce": 0.07018, "rouge_s*_f_score": 0.06299, "rouge_s*_f_score_cb": 0.06299, "rouge_s*_f_score_ce": 0.06299, "rouge_su*_recall": 0.07826, "rouge_su*_recall_cb": 0.07826, "rouge_su*_recall_ce": 0.07826, "rouge_su*_precision": 0.09524, "rouge_su*_precision_cb": 0.09524, "rouge_su*_precision_ce": 0.09524, "rouge_su*_f_score": 0.08592, "rouge_su*_f_score_cb": 0.08592, "rouge_su*_f_score_ce": 0.08592}, "TConvS2S_bleu": 5.618923497225256, "TConvS2S_meteor": 0.09999024466708277, "PtGen_rouge": {"rouge_1_recall": 0.2381, "rouge_1_recall_cb": 0.2381, "rouge_1_recall_ce": 0.2381, "rouge_1_precision": 0.26316, "rouge_1_precision_cb": 0.26316, "rouge_1_precision_ce": 0.26316, "rouge_1_f_score": 0.25, "rouge_1_f_score_cb": 0.25, "rouge_1_f_score_ce": 0.25, "rouge_2_recall": 0.05, "rouge_2_recall_cb": 0.05, "rouge_2_recall_ce": 0.05, "rouge_2_precision": 0.05556, "rouge_2_precision_cb": 0.05556, "rouge_2_precision_ce": 0.05556, "rouge_2_f_score": 0.05263, "rouge_2_f_score_cb": 0.05263, "rouge_2_f_score_ce": 0.05263, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.09524, "rouge_l_recall_cb": 0.09524, "rouge_l_recall_ce": 0.09524, "rouge_l_precision": 0.10526, "rouge_l_precision_cb": 0.10526, "rouge_l_precision_ce": 0.10526, "rouge_l_f_score": 0.1, "rouge_l_f_score_cb": 0.1, "rouge_l_f_score_ce": 0.1, "rouge_w_1.2_recall": 0.0518, "rouge_w_1.2_recall_cb": 0.0518, "rouge_w_1.2_recall_ce": 0.0518, "rouge_w_1.2_precision": 0.10526, "rouge_w_1.2_precision_cb": 0.10526, "rouge_w_1.2_precision_ce": 0.10526, "rouge_w_1.2_f_score": 0.06943, "rouge_w_1.2_f_score_cb": 0.06943, "rouge_w_1.2_f_score_ce": 0.06943, "rouge_s*_recall": 0.01905, "rouge_s*_recall_cb": 0.01905, "rouge_s*_recall_ce": 0.01905, "rouge_s*_precision": 0.02339, "rouge_s*_precision_cb": 0.02339, "rouge_s*_precision_ce": 0.02339, "rouge_s*_f_score": 0.021, "rouge_s*_f_score_cb": 0.021, "rouge_s*_f_score_ce": 0.021, "rouge_su*_recall": 0.03913, "rouge_su*_recall_cb": 0.03913, "rouge_su*_recall_ce": 0.03913, "rouge_su*_precision": 0.04762, "rouge_su*_precision_cb": 0.04762, "rouge_su*_precision_ce": 0.04762, "rouge_su*_f_score": 0.04296, "rouge_su*_f_score_cb": 0.04296, "rouge_su*_f_score_ce": 0.04296}, "PtGen_bleu": 4.793738461810042, "PtGen_meteor": 0.07204863206810659, "TranS2S_rouge": {"rouge_1_recall": 0.2381, "rouge_1_recall_cb": 0.2381, "rouge_1_recall_ce": 0.2381, "rouge_1_precision": 0.29412, "rouge_1_precision_cb": 0.29412, "rouge_1_precision_ce": 0.29412, "rouge_1_f_score": 0.26316, "rouge_1_f_score_cb": 0.26316, "rouge_1_f_score_ce": 0.26316, "rouge_2_recall": 0.0, "rouge_2_recall_cb": 0.0, "rouge_2_recall_ce": 0.0, "rouge_2_precision": 0.0, "rouge_2_precision_cb": 0.0, "rouge_2_precision_ce": 0.0, "rouge_2_f_score": 0.0, "rouge_2_f_score_cb": 0.0, "rouge_2_f_score_ce": 0.0, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.14286, "rouge_l_recall_cb": 0.14286, "rouge_l_recall_ce": 0.14286, "rouge_l_precision": 0.17647, "rouge_l_precision_cb": 0.17647, "rouge_l_precision_ce": 0.17647, "rouge_l_f_score": 0.1579, "rouge_l_f_score_cb": 0.1579, "rouge_l_f_score_ce": 0.1579, "rouge_w_1.2_recall": 0.06471, "rouge_w_1.2_recall_cb": 0.06471, "rouge_w_1.2_recall_ce": 0.06471, "rouge_w_1.2_precision": 0.14694, "rouge_w_1.2_precision_cb": 0.14694, "rouge_w_1.2_precision_ce": 0.14694, "rouge_w_1.2_f_score": 0.08985, "rouge_w_1.2_f_score_cb": 0.08985, "rouge_w_1.2_f_score_ce": 0.08985, "rouge_s*_recall": 0.0381, "rouge_s*_recall_cb": 0.0381, "rouge_s*_recall_ce": 0.0381, "rouge_s*_precision": 0.05882, "rouge_s*_precision_cb": 0.05882, "rouge_s*_precision_ce": 0.05882, "rouge_s*_f_score": 0.04625, "rouge_s*_f_score_cb": 0.04625, "rouge_s*_f_score_ce": 0.04625, "rouge_su*_recall": 0.05217, "rouge_su*_recall_cb": 0.05217, "rouge_su*_recall_ce": 0.05217, "rouge_su*_precision": 0.07895, "rouge_su*_precision_cb": 0.07895, "rouge_su*_precision_ce": 0.07895, "rouge_su*_f_score": 0.06283, "rouge_su*_f_score_cb": 0.06283, "rouge_su*_f_score_ce": 0.06283}, "TranS2S_bleu": 2.8518643084013244, "TranS2S_meteor": 0.08438818565400844}