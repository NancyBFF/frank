{"BERTS2S": "a campaign to raise \u00a350, 000 for british troops killed in the iraq war has reached \u00a350, 000.", "BERTS2S_lines": ["a campaign to raise \u00a350, 000 for british troops killed in the iraq war has reached \u00a350, 000."], "TConvS2S": "a campaign to raise funds for the iraq war has been launched by the uk government.", "TConvS2S_lines": ["a campaign to raise funds for the iraq war has been launched by the uk government."], "Gold": "an online campaign to fund possible legal action against former prime minister tony blair and other officials has reached its target of # 150,000.", "Gold_lines": ["an online campaign to fund possible legal action against former prime minister tony blair and other officials has reached its target of # 150,000."], "PtGen": "the chilcot campaign group has said it is ``startling and humbling\\'\\'by the chilcot report to fund the chilcot report.", "PtGen_lines": ["the chilcot campaign group has said it is ``startling and humbling\\'\\'by", "the chilcot report to fund the chilcot report."], "TranS2S": "the families of british troops killed in the 2003 iraq war have launched a campaign to raise funds for the chilcot report.", "TranS2S_lines": ["the families of british troops killed in the 2003 iraq war have launched a campaign to raise funds for the chilcot report."], "article": "Share this withEmailFacebookTwitterPinterestWhatsAppLinkedinCopy this linkThe campaign was launched on 19 July by the Iraq War Families Campaign Group, which is made up of relatives of British troops killed in the conflict.It aimed to reach that amount to \"bring to justice those responsible for the war and the deaths of our loved ones\".The campaign was led by Reg Keys and Roger Bacon, who lost sons in Iraq.The funding bid began after the publication last month of the long-awaited report by Sir John Chilcot into the 2003 invasion.Chilcot report: Findings at-a-glanceThe campaign group initially aimed to reach \u00a350,000 via crowdfunding, but extended its target after raising that figure in nine hours on the CrowdJustice website.It has now received enough backing to fund the whole campaign.Mr Keys and Mr Bacon said in a statement: \"This is great proof of the underlying support from the British people in our quest for answers and for justice.\"It is startling and humbling at the same time.\"The money raised will allow the group's lawyers, McCue and Partners - currently working free of charge - to analyse the 2.6 million-word report by Sir John and prepare \"a comprehensive opinion approved by expert senior counsel\".This would provide guidance on whether legal action against key people involved in the invasion of Iraq would succeed or not.The Chilcot report did not make any findings on whether individuals acted unlawfully.However, it rejected the legal basis for UK military action, and said then-prime minister Mr Blair overstated the threat posed by then-President of Iraq Saddam Hussein and sent ill-prepared troops into battle.Chilcot report: Coverage in fullMr Blair has apologised for any mistakes made, but not the decision to go to war itself.A total of 179 British service personnel were killed in Iraq between 2003 and 2009, when British troops left Iraqi soil.Tens of thousands of Iraqi civilians died over the period, though estimates vary considerably.", "article_lines": ["Share this withEmailFacebookTwitterPinterestWhatsAppLinkedinCopy this linkThe campaign was launched on 19 July by the Iraq War Families Campaign Group, which is made up of relatives of British troops killed in the conflict.", "It aimed to reach that amount to \"bring to justice those responsible for the war and the deaths of our loved ones\".", "The campaign was led by Reg Keys and Roger Bacon, who lost sons in Iraq.", "The funding bid began after the publication last month of the long-awaited report by Sir John Chilcot into the 2003 invasion.", "Chilcot report:", "Findings at-a-glanceThe campaign group initially aimed to reach \u00a350,000 via crowdfunding, but extended its target after raising that figure in nine hours on the CrowdJustice website.", "It has now received enough backing to fund the whole campaign.", "Mr Keys and Mr Bacon said in a statement: \"This is great proof of the underlying support from the British people in our quest for answers and for justice.", "\"It is startling and humbling at the same time.", "\"The", "money raised will allow the group's lawyers, McCue and Partners - currently working free of charge - to analyse the 2.6 million-word report by Sir John and prepare \"a comprehensive opinion approved by expert senior counsel\".", "This would provide guidance on whether legal action against key people involved in the invasion of Iraq would succeed or not.", "The Chilcot report did not make any findings on whether individuals acted unlawfully.", "However, it rejected the legal basis for UK military action, and said then-prime minister Mr Blair overstated the threat posed by then-President of Iraq Saddam Hussein and sent ill-prepared troops into battle.", "Chilcot report:", "Coverage in fullMr Blair has apologised for any mistakes made, but not the decision to go to war itself.", "A total of 179 British service personnel were killed in Iraq between 2003 and 2009, when British troops left Iraqi soil.", "Tens of thousands of Iraqi civilians died over the period, though estimates vary considerably."], "entity_counter": {"this withEmailFacebookTwitterPinterestWhatsAppLinkedinCopy": 1, "this linkThe campaign": 2, "the Iraq War Families Campaign Group": 1, "relatives": 1, "British troops": 2, "the conflict": 1, "that amount": 1, "justice": 2, "the war": 1, "the deaths": 1, "our loved ones\"": 1, "Reg Keys": 1, "Roger Bacon": 1, "sons": 1, "Iraq": 4, "The funding bid": 1, "the publication": 1, "the long-awaited report": 1, "Sir John Chilcot": 2, "the 2003 invasion": 1, "a-glanceThe": 1, "crowdfunding": 1, "its target": 1, "that figure": 1, "the CrowdJustice website": 1, "enough backing": 1, "the whole campaign": 1, "Mr Keys": 1, "Mr Bacon": 1, "a statement": 1, "great proof": 1, "the underlying support": 1, "the British people": 1, "our quest": 1, "answers": 1, "the same time": 1, "money": 1, "the group's lawyers": 1, "McCue": 1, "Partners": 1, "charge": 1, "the 2.6 million-word report": 1, "Sir John": 1, "a comprehensive opinion": 1, "expert senior": 1, "guidance": 1, "legal action": 1, "key people": 1, "the invasion": 1, "the long-awaited report by Sir John Chilcot into the 2003 invasion": 1, "any findings": 1, "individuals": 1, "the legal basis": 1, "UK military action": 1, "then-prime minister Mr Blair": 2, "the threat": 1, "ill-prepared troops": 1, "battle": 1, "Chilcot": 1, "Coverage": 1, "any mistakes": 1, "not the decision": 1, "war": 1, "A total": 1, "179 British service personnel": 1, "Iraqi soil": 1, "Iraqi civilians": 1, "the period": 1, "estimates": 1}, "negative_entity": "Tokyo", "url": "http://web.archive.org/web/20160806103208/http://www.bbc.com/news/uk-36968311", "hash": "36968311", "traps": [["F6", "findings at-a-glancethe campaign group initially aimed to reach \u00a350,000 via crowdfunding, but extended your target after raising that figure in nine hours on the crowdjustice website."], ["F5", "a troops chilcot which in campaign."], ["F0", "share this withemailfacebooktwitterpinterestwhatsapplinkedincopy this linkthe campaign was launched on 19 july by the iraq war families campaign group, which is made up of relatives of british troops killed in the conflict."], ["F4", "the incident happened near dr gray's hospital shortly after 10:00.the man was taken to the hospital with what police said were serious but not life-threatening injuries."], ["F0", "share this withemailfacebooktwitterpinterestwhatsapplinkedincopy this linkthe campaign was launched on 19 july by the iraq war families campaign group, which is made up of relatives of british troops killed in the conflict."], ["F0", "share this withemailfacebooktwitterpinterestwhatsapplinkedincopy this linkthe campaign was launched on 19 july by the iraq war families campaign group, which is made up of relatives of british troops killed in the conflict."]], "model_names": ["BERTS2S_lines", "TConvS2S_lines", "Gold_lines", "PtGen_lines", "TranS2S_lines"], "BERTS2S_rouge": {"rouge_1_recall": 0.20833, "rouge_1_recall_cb": 0.20833, "rouge_1_recall_ce": 0.20833, "rouge_1_precision": 0.27778, "rouge_1_precision_cb": 0.27778, "rouge_1_precision_ce": 0.27778, "rouge_1_f_score": 0.23809, "rouge_1_f_score_cb": 0.23809, "rouge_1_f_score_ce": 0.23809, "rouge_2_recall": 0.08696, "rouge_2_recall_cb": 0.08696, "rouge_2_recall_ce": 0.08696, "rouge_2_precision": 0.11765, "rouge_2_precision_cb": 0.11765, "rouge_2_precision_ce": 0.11765, "rouge_2_f_score": 0.1, "rouge_2_f_score_cb": 0.1, "rouge_2_f_score_ce": 0.1, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.20833, "rouge_l_recall_cb": 0.20833, "rouge_l_recall_ce": 0.20833, "rouge_l_precision": 0.27778, "rouge_l_precision_cb": 0.27778, "rouge_l_precision_ce": 0.27778, "rouge_l_f_score": 0.23809, "rouge_l_f_score_cb": 0.23809, "rouge_l_f_score_ce": 0.23809, "rouge_w_1.2_recall": 0.09266, "rouge_w_1.2_recall_cb": 0.09266, "rouge_w_1.2_recall_ce": 0.09266, "rouge_w_1.2_precision": 0.23328, "rouge_w_1.2_precision_cb": 0.23328, "rouge_w_1.2_precision_ce": 0.23328, "rouge_w_1.2_f_score": 0.13264, "rouge_w_1.2_f_score_cb": 0.13264, "rouge_w_1.2_f_score_ce": 0.13264, "rouge_s*_recall": 0.03623, "rouge_s*_recall_cb": 0.03623, "rouge_s*_recall_ce": 0.03623, "rouge_s*_precision": 0.06536, "rouge_s*_precision_cb": 0.06536, "rouge_s*_precision_ce": 0.06536, "rouge_s*_f_score": 0.04662, "rouge_s*_f_score_cb": 0.04662, "rouge_s*_f_score_ce": 0.04662, "rouge_su*_recall": 0.04682, "rouge_su*_recall_cb": 0.04682, "rouge_su*_recall_ce": 0.04682, "rouge_su*_precision": 0.08235, "rouge_su*_precision_cb": 0.08235, "rouge_su*_precision_ce": 0.08235, "rouge_su*_f_score": 0.0597, "rouge_su*_f_score_cb": 0.0597, "rouge_su*_f_score_ce": 0.0597}, "BERTS2S_bleu": 4.4893751230471235, "BERTS2S_meteor": 0.07135718965716012, "TConvS2S_rouge": {"rouge_1_recall": 0.16667, "rouge_1_recall_cb": 0.16667, "rouge_1_recall_ce": 0.16667, "rouge_1_precision": 0.25, "rouge_1_precision_cb": 0.25, "rouge_1_precision_ce": 0.25, "rouge_1_f_score": 0.2, "rouge_1_f_score_cb": 0.2, "rouge_1_f_score_ce": 0.2, "rouge_2_recall": 0.04348, "rouge_2_recall_cb": 0.04348, "rouge_2_recall_ce": 0.04348, "rouge_2_precision": 0.06667, "rouge_2_precision_cb": 0.06667, "rouge_2_precision_ce": 0.06667, "rouge_2_f_score": 0.05263, "rouge_2_f_score_cb": 0.05263, "rouge_2_f_score_ce": 0.05263, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.16667, "rouge_l_recall_cb": 0.16667, "rouge_l_recall_ce": 0.16667, "rouge_l_precision": 0.25, "rouge_l_precision_cb": 0.25, "rouge_l_precision_ce": 0.25, "rouge_l_f_score": 0.2, "rouge_l_f_score_cb": 0.2, "rouge_l_f_score_ce": 0.2, "rouge_w_1.2_recall": 0.08066, "rouge_w_1.2_recall_cb": 0.08066, "rouge_w_1.2_recall_ce": 0.08066, "rouge_w_1.2_precision": 0.22846, "rouge_w_1.2_precision_cb": 0.22846, "rouge_w_1.2_precision_ce": 0.22846, "rouge_w_1.2_f_score": 0.11923, "rouge_w_1.2_f_score_cb": 0.11923, "rouge_w_1.2_f_score_ce": 0.11923, "rouge_s*_recall": 0.02174, "rouge_s*_recall_cb": 0.02174, "rouge_s*_recall_ce": 0.02174, "rouge_s*_precision": 0.05, "rouge_s*_precision_cb": 0.05, "rouge_s*_precision_ce": 0.05, "rouge_s*_f_score": 0.0303, "rouge_s*_f_score_cb": 0.0303, "rouge_s*_f_score_ce": 0.0303, "rouge_su*_recall": 0.03344, "rouge_su*_recall_cb": 0.03344, "rouge_su*_recall_ce": 0.03344, "rouge_su*_precision": 0.07407, "rouge_su*_precision_cb": 0.07407, "rouge_su*_precision_ce": 0.07407, "rouge_su*_f_score": 0.04608, "rouge_su*_f_score_cb": 0.04608, "rouge_su*_f_score_ce": 0.04608}, "TConvS2S_bleu": 3.397594755073535, "TConvS2S_meteor": 0.062264861825191364, "PtGen_rouge": {"rouge_1_recall": 0.20833, "rouge_1_recall_cb": 0.20833, "rouge_1_recall_ce": 0.20833, "rouge_1_precision": 0.25, "rouge_1_precision_cb": 0.25, "rouge_1_precision_ce": 0.25, "rouge_1_f_score": 0.22727, "rouge_1_f_score_cb": 0.22727, "rouge_1_f_score_ce": 0.22727, "rouge_2_recall": 0.04348, "rouge_2_recall_cb": 0.04348, "rouge_2_recall_ce": 0.04348, "rouge_2_precision": 0.05263, "rouge_2_precision_cb": 0.05263, "rouge_2_precision_ce": 0.05263, "rouge_2_f_score": 0.04762, "rouge_2_f_score_cb": 0.04762, "rouge_2_f_score_ce": 0.04762, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.125, "rouge_l_recall_cb": 0.125, "rouge_l_recall_ce": 0.125, "rouge_l_precision": 0.15, "rouge_l_precision_cb": 0.15, "rouge_l_precision_ce": 0.15, "rouge_l_f_score": 0.13636, "rouge_l_f_score_cb": 0.13636, "rouge_l_f_score_ce": 0.13636, "rouge_w_1.2_recall": 0.0662, "rouge_w_1.2_recall_cb": 0.0662, "rouge_w_1.2_recall_ce": 0.0662, "rouge_w_1.2_precision": 0.15, "rouge_w_1.2_precision_cb": 0.15, "rouge_w_1.2_precision_ce": 0.15, "rouge_w_1.2_f_score": 0.09186, "rouge_w_1.2_f_score_cb": 0.09186, "rouge_w_1.2_f_score_ce": 0.09186, "rouge_s*_recall": 0.01812, "rouge_s*_recall_cb": 0.01812, "rouge_s*_recall_ce": 0.01812, "rouge_s*_precision": 0.02632, "rouge_s*_precision_cb": 0.02632, "rouge_s*_precision_ce": 0.02632, "rouge_s*_f_score": 0.02146, "rouge_s*_f_score_cb": 0.02146, "rouge_s*_f_score_ce": 0.02146, "rouge_su*_recall": 0.03344, "rouge_su*_recall_cb": 0.03344, "rouge_su*_recall_ce": 0.03344, "rouge_su*_precision": 0.04785, "rouge_su*_precision_cb": 0.04785, "rouge_su*_precision_ce": 0.04785, "rouge_su*_f_score": 0.03937, "rouge_su*_f_score_cb": 0.03937, "rouge_su*_f_score_ce": 0.03937}, "PtGen_bleu": 3.802351022611669, "PtGen_meteor": 0.07311092759729812, "TranS2S_rouge": {"rouge_1_recall": 0.16667, "rouge_1_recall_cb": 0.16667, "rouge_1_recall_ce": 0.16667, "rouge_1_precision": 0.18182, "rouge_1_precision_cb": 0.18182, "rouge_1_precision_ce": 0.18182, "rouge_1_f_score": 0.17392, "rouge_1_f_score_cb": 0.17392, "rouge_1_f_score_ce": 0.17392, "rouge_2_recall": 0.04348, "rouge_2_recall_cb": 0.04348, "rouge_2_recall_ce": 0.04348, "rouge_2_precision": 0.04762, "rouge_2_precision_cb": 0.04762, "rouge_2_precision_ce": 0.04762, "rouge_2_f_score": 0.04546, "rouge_2_f_score_cb": 0.04546, "rouge_2_f_score_ce": 0.04546, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.125, "rouge_l_recall_cb": 0.125, "rouge_l_recall_ce": 0.125, "rouge_l_precision": 0.13636, "rouge_l_precision_cb": 0.13636, "rouge_l_precision_ce": 0.13636, "rouge_l_f_score": 0.13043, "rouge_l_f_score_cb": 0.13043, "rouge_l_f_score_ce": 0.13043, "rouge_w_1.2_recall": 0.0662, "rouge_w_1.2_recall_cb": 0.0662, "rouge_w_1.2_recall_ce": 0.0662, "rouge_w_1.2_precision": 0.13636, "rouge_w_1.2_precision_cb": 0.13636, "rouge_w_1.2_precision_ce": 0.13636, "rouge_w_1.2_f_score": 0.08913, "rouge_w_1.2_f_score_cb": 0.08913, "rouge_w_1.2_f_score_ce": 0.08913, "rouge_s*_recall": 0.01087, "rouge_s*_recall_cb": 0.01087, "rouge_s*_recall_ce": 0.01087, "rouge_s*_precision": 0.01299, "rouge_s*_precision_cb": 0.01299, "rouge_s*_precision_ce": 0.01299, "rouge_s*_f_score": 0.01184, "rouge_s*_f_score_cb": 0.01184, "rouge_s*_f_score_ce": 0.01184, "rouge_su*_recall": 0.02341, "rouge_su*_recall_cb": 0.02341, "rouge_su*_recall_ce": 0.02341, "rouge_su*_precision": 0.02778, "rouge_su*_precision_cb": 0.02778, "rouge_su*_precision_ce": 0.02778, "rouge_su*_f_score": 0.02541, "rouge_su*_f_score_cb": 0.02541, "rouge_su*_f_score_ce": 0.02541}, "TranS2S_bleu": 3.5902757996620975, "TranS2S_meteor": 0.06601438826154614}