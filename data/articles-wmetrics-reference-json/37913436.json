{"BERTS2S": "a proposal to pardon gay and bisexual men convicted of sexual offences in northern ireland has been approved by the northern ireland assembly.", "BERTS2S_lines": ["a proposal to pardon gay and bisexual men convicted of sexual offences in northern ireland has been approved by the northern ireland assembly."], "TConvS2S": "the northern ireland assembly has voted to introduce legislation to allow gay men to be convicted of sex offences.", "TConvS2S_lines": ["the northern ireland assembly has voted to introduce legislation to allow gay men to be convicted of sex offences."], "Gold": "gay and bisexual men convicted of abolished sex offences in northern ireland look set to be pardoned.", "Gold_lines": ["gay and bisexual men convicted of abolished sex offences in northern ireland look set to be pardoned."], "PtGen": "the assembly\\'s assembly has approved a motion to pardon convictions for gay and bisexual men in england and wales.", "PtGen_lines": ["the assembly\\'s assembly has approved a motion to pardon convictions for gay and bisexual men in england and wales."], "TranS2S": "gay and bisexual men convicted of sexually abusing gay men will be pardoned from next year, the government has confirmed.", "TranS2S_lines": ["gay and bisexual men convicted of sexually abusing gay men will be pardoned from next year, the government has confirmed."], "article": "Share this withEmailFacebookMessengerMessengerTwitterPinterestWhatsAppLinkedinCopy this linkJustice Minister Claire Sugden confirmed a motion will go before the assembly for approval.The move will bring Northern Ireland in line with England and Wales, where plans for automatic pardons were announced last month.Those proposals would see men convicted of now-abolished sexual offences receive posthumous pardons.Dubbed 'Turing's Law', after the World War Two code-breaker Alan Turing, the law will also allow living men convicted of such offences to apply for a pardon.The motion in the assembly is expected to contain the same provisions and allow for pardons both posthumously as well as for living gay and bisexual men.The minister said she has secured executive agreement to ask the assembly to pass a legislative consent motion to pardon convictions related to abolished sexual offences.Ms Sugden said that arrangements would be brought in \"as soon as possible to ensure that there is equal treatment for gay and bisexual men here as for their counterparts in England and Wales\".\"This is an opportunity for the criminal justice system to try and right the wrongs of the past and one which will allow for much earlier resolve than that presented by way of an assembly bill,\" she added.The motion will now go forward for consideration by the assembly.", "article_lines": ["Share this withEmailFacebookMessengerMessengerTwitterPinterestWhatsAppLinkedinCopy", "this linkJustice Minister Claire Sugden confirmed a motion will go before the assembly for approval.", "The move will bring Northern Ireland in line with England and Wales, where plans for automatic pardons were announced last month.", "Those proposals would see men convicted of now-abolished sexual offences receive posthumous pardons.", "Dubbed 'Turing's Law', after the World War Two code-breaker Alan Turing, the law will also allow living men convicted of such offences to apply for a pardon.", "The motion in the assembly is expected to contain the same provisions and allow for pardons both posthumously as well as for living gay and bisexual men.", "The minister said she has secured executive agreement to ask the assembly to pass a legislative consent motion to pardon convictions related to abolished sexual offences.", "Ms Sugden said that arrangements would be brought in \"as soon as possible to ensure that there is equal treatment for gay and bisexual men here as for their counterparts in England and Wales\".", "\"This is an opportunity for the criminal justice system to try and right the wrongs of the past and one which will allow for much earlier resolve than that presented by way of an assembly bill,\" she added.", "The motion will now go forward for consideration by the assembly."], "entity_counter": {"this withEmailFacebookMessengerMessengerTwitterPinterestWhatsAppLinkedinCopy": 1, "this linkJustice Minister Claire Sugden": 3, "a motion": 2, "the assembly": 4, "approval": 1, "The move": 1, "Northern Ireland": 1, "line": 1, "England": 2, "Wales": 1, "plans": 1, "automatic pardons": 1, "Northern Ireland in line with England and Wales, where plans for automatic pardons were announced last month": 1, "men": 1, "now-abolished sexual offences": 1, "posthumous pardons": 1, "Turing's Law": 1, "the World War Two code-breaker": 1, "Alan Turing": 1, "Turing's Law'": 1, "living men": 1, "such offences": 1, "a pardon": 1, "The motion": 1, "the same provisions": 1, "pardons": 1, "gay and bisexual men": 2, "executive agreement": 1, "a legislative consent motion": 1, "convictions": 1, "sexual offences": 1, "arrangements": 1, "equal treatment": 1, "their counterparts": 1, "Wales\"": 1, "\"This": 1, "an opportunity": 1, "the criminal justice system": 1, "the wrongs": 1, "the past": 1, "much earlier resolve": 1, "way": 1, "an assembly bill": 1, "consideration": 1}, "negative_entity": "John", "url": "http://web.archive.org/web/20161108234421/http://www.bbc.com/news/uk-northern-ireland-37913436", "hash": "37913436", "traps": [["F6", "ms sugden said that arrangements would be brought in \"as soon as possible to ensure that there is equal treatment for gay and bisexual men here as for our counterparts in england and wales\"."], ["F5", "way in resolve offences motion pardons turing soon the try agreement offences right which bring."], ["F0", "share this withemailfacebookmessengermessengertwitterpinterestwhatsapplinkedincopy"], ["F4", "the department for environment, food and rural affairs found the number had gone up by 200 million since 2013.there has been a big problem with plastic carrier bags in the last few years, many of them can't be recycled and are often thrown away after they have been used."], ["F6", "the minister said he has secured executive agreement to ask the assembly to pass a legislative consent motion to pardon convictions related to abolished sexual offences."], ["F1", "this linkjustice minister claire sugden confirmed a motion will not go before the assembly for approval ."]], "model_names": ["BERTS2S_lines", "TConvS2S_lines", "Gold_lines", "PtGen_lines", "TranS2S_lines"], "BERTS2S_rouge": {"rouge_1_recall": 0.70588, "rouge_1_recall_cb": 0.70588, "rouge_1_recall_ce": 0.70588, "rouge_1_precision": 0.52174, "rouge_1_precision_cb": 0.52174, "rouge_1_precision_ce": 0.52174, "rouge_1_f_score": 0.6, "rouge_1_f_score_cb": 0.6, "rouge_1_f_score_ce": 0.6, "rouge_2_recall": 0.5, "rouge_2_recall_cb": 0.5, "rouge_2_recall_ce": 0.5, "rouge_2_precision": 0.36364, "rouge_2_precision_cb": 0.36364, "rouge_2_precision_ce": 0.36364, "rouge_2_f_score": 0.42106, "rouge_2_f_score_cb": 0.42106, "rouge_2_f_score_ce": 0.42106, "rouge_3_recall": 0.4, "rouge_3_recall_cb": 0.4, "rouge_3_recall_ce": 0.4, "rouge_3_precision": 0.28571, "rouge_3_precision_cb": 0.28571, "rouge_3_precision_ce": 0.28571, "rouge_3_f_score": 0.33333, "rouge_3_f_score_cb": 0.33333, "rouge_3_f_score_ce": 0.33333, "rouge_4_recall": 0.28571, "rouge_4_recall_cb": 0.28571, "rouge_4_recall_ce": 0.28571, "rouge_4_precision": 0.2, "rouge_4_precision_cb": 0.2, "rouge_4_precision_ce": 0.2, "rouge_4_f_score": 0.23529, "rouge_4_f_score_cb": 0.23529, "rouge_4_f_score_ce": 0.23529, "rouge_l_recall": 0.58824, "rouge_l_recall_cb": 0.58824, "rouge_l_recall_ce": 0.58824, "rouge_l_precision": 0.43478, "rouge_l_precision_cb": 0.43478, "rouge_l_precision_ce": 0.43478, "rouge_l_f_score": 0.5, "rouge_l_f_score_cb": 0.5, "rouge_l_f_score_ce": 0.5, "rouge_w_1.2_recall": 0.29856, "rouge_w_1.2_recall_cb": 0.29856, "rouge_w_1.2_recall_ce": 0.29856, "rouge_w_1.2_precision": 0.3889, "rouge_w_1.2_precision_cb": 0.3889, "rouge_w_1.2_precision_ce": 0.3889, "rouge_w_1.2_f_score": 0.33779, "rouge_w_1.2_f_score_cb": 0.33779, "rouge_w_1.2_f_score_ce": 0.33779, "rouge_s*_recall": 0.33824, "rouge_s*_recall_cb": 0.33824, "rouge_s*_recall_ce": 0.33824, "rouge_s*_precision": 0.18182, "rouge_s*_precision_cb": 0.18182, "rouge_s*_precision_ce": 0.18182, "rouge_s*_f_score": 0.23651, "rouge_s*_f_score_cb": 0.23651, "rouge_s*_f_score_ce": 0.23651, "rouge_su*_recall": 0.375, "rouge_su*_recall_cb": 0.375, "rouge_su*_recall_ce": 0.375, "rouge_su*_precision": 0.20727, "rouge_su*_precision_cb": 0.20727, "rouge_su*_precision_ce": 0.20727, "rouge_su*_f_score": 0.26698, "rouge_su*_f_score_cb": 0.26698, "rouge_su*_f_score_ce": 0.26698}, "BERTS2S_bleu": 30.8301299550215, "BERTS2S_meteor": 0.33640370975003836, "TConvS2S_rouge": {"rouge_1_recall": 0.58824, "rouge_1_recall_cb": 0.58824, "rouge_1_recall_ce": 0.58824, "rouge_1_precision": 0.52632, "rouge_1_precision_cb": 0.52632, "rouge_1_precision_ce": 0.52632, "rouge_1_f_score": 0.55556, "rouge_1_f_score_cb": 0.55556, "rouge_1_f_score_ce": 0.55556, "rouge_2_recall": 0.25, "rouge_2_recall_cb": 0.25, "rouge_2_recall_ce": 0.25, "rouge_2_precision": 0.22222, "rouge_2_precision_cb": 0.22222, "rouge_2_precision_ce": 0.22222, "rouge_2_f_score": 0.23529, "rouge_2_f_score_cb": 0.23529, "rouge_2_f_score_ce": 0.23529, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.35294, "rouge_l_recall_cb": 0.35294, "rouge_l_recall_ce": 0.35294, "rouge_l_precision": 0.31579, "rouge_l_precision_cb": 0.31579, "rouge_l_precision_ce": 0.31579, "rouge_l_f_score": 0.33333, "rouge_l_f_score_cb": 0.33333, "rouge_l_f_score_ce": 0.33333, "rouge_w_1.2_recall": 0.16963, "rouge_w_1.2_recall_cb": 0.16963, "rouge_w_1.2_recall_ce": 0.16963, "rouge_w_1.2_precision": 0.26747, "rouge_w_1.2_precision_cb": 0.26747, "rouge_w_1.2_precision_ce": 0.26747, "rouge_w_1.2_f_score": 0.2076, "rouge_w_1.2_f_score_cb": 0.2076, "rouge_w_1.2_f_score_ce": 0.2076, "rouge_s*_recall": 0.18382, "rouge_s*_recall_cb": 0.18382, "rouge_s*_recall_ce": 0.18382, "rouge_s*_precision": 0.1462, "rouge_s*_precision_cb": 0.1462, "rouge_s*_precision_ce": 0.1462, "rouge_s*_f_score": 0.16287, "rouge_s*_f_score_cb": 0.16287, "rouge_s*_f_score_ce": 0.16287, "rouge_su*_recall": 0.22368, "rouge_su*_recall_cb": 0.22368, "rouge_su*_recall_ce": 0.22368, "rouge_su*_precision": 0.17989, "rouge_su*_precision_cb": 0.17989, "rouge_su*_precision_ce": 0.17989, "rouge_su*_f_score": 0.19941, "rouge_su*_f_score_cb": 0.19941, "rouge_su*_f_score_ce": 0.19941}, "TConvS2S_bleu": 8.29305253557858, "TConvS2S_meteor": 0.26705612151531233, "PtGen_rouge": {"rouge_1_recall": 0.47059, "rouge_1_recall_cb": 0.47059, "rouge_1_recall_ce": 0.47059, "rouge_1_precision": 0.4, "rouge_1_precision_cb": 0.4, "rouge_1_precision_ce": 0.4, "rouge_1_f_score": 0.43243, "rouge_1_f_score_cb": 0.43243, "rouge_1_f_score_ce": 0.43243, "rouge_2_recall": 0.1875, "rouge_2_recall_cb": 0.1875, "rouge_2_recall_ce": 0.1875, "rouge_2_precision": 0.15789, "rouge_2_precision_cb": 0.15789, "rouge_2_precision_ce": 0.15789, "rouge_2_f_score": 0.17143, "rouge_2_f_score_cb": 0.17143, "rouge_2_f_score_ce": 0.17143, "rouge_3_recall": 0.13333, "rouge_3_recall_cb": 0.13333, "rouge_3_recall_ce": 0.13333, "rouge_3_precision": 0.11111, "rouge_3_precision_cb": 0.11111, "rouge_3_precision_ce": 0.11111, "rouge_3_f_score": 0.12121, "rouge_3_f_score_cb": 0.12121, "rouge_3_f_score_ce": 0.12121, "rouge_4_recall": 0.07143, "rouge_4_recall_cb": 0.07143, "rouge_4_recall_ce": 0.07143, "rouge_4_precision": 0.05882, "rouge_4_precision_cb": 0.05882, "rouge_4_precision_ce": 0.05882, "rouge_4_f_score": 0.06451, "rouge_4_f_score_cb": 0.06451, "rouge_4_f_score_ce": 0.06451, "rouge_l_recall": 0.29412, "rouge_l_recall_cb": 0.29412, "rouge_l_recall_ce": 0.29412, "rouge_l_precision": 0.25, "rouge_l_precision_cb": 0.25, "rouge_l_precision_ce": 0.25, "rouge_l_f_score": 0.27027, "rouge_l_f_score_cb": 0.27027, "rouge_l_f_score_ce": 0.27027, "rouge_w_1.2_recall": 0.15428, "rouge_w_1.2_recall_cb": 0.15428, "rouge_w_1.2_recall_ce": 0.15428, "rouge_w_1.2_precision": 0.23111, "rouge_w_1.2_precision_cb": 0.23111, "rouge_w_1.2_precision_ce": 0.23111, "rouge_w_1.2_f_score": 0.18504, "rouge_w_1.2_f_score_cb": 0.18504, "rouge_w_1.2_f_score_ce": 0.18504, "rouge_s*_recall": 0.08824, "rouge_s*_recall_cb": 0.08824, "rouge_s*_recall_ce": 0.08824, "rouge_s*_precision": 0.06316, "rouge_s*_precision_cb": 0.06316, "rouge_s*_precision_ce": 0.06316, "rouge_s*_f_score": 0.07362, "rouge_s*_f_score_cb": 0.07362, "rouge_s*_f_score_ce": 0.07362, "rouge_su*_recall": 0.125, "rouge_su*_recall_cb": 0.125, "rouge_su*_recall_ce": 0.125, "rouge_su*_precision": 0.09091, "rouge_su*_precision_cb": 0.09091, "rouge_su*_precision_ce": 0.09091, "rouge_su*_f_score": 0.10526, "rouge_su*_f_score_cb": 0.10526, "rouge_su*_f_score_ce": 0.10526}, "PtGen_bleu": 12.436722085116983, "PtGen_meteor": 0.16806579382780057, "TranS2S_rouge": {"rouge_1_recall": 0.47059, "rouge_1_recall_cb": 0.47059, "rouge_1_recall_ce": 0.47059, "rouge_1_precision": 0.4, "rouge_1_precision_cb": 0.4, "rouge_1_precision_ce": 0.4, "rouge_1_f_score": 0.43243, "rouge_1_f_score_cb": 0.43243, "rouge_1_f_score_ce": 0.43243, "rouge_2_recall": 0.375, "rouge_2_recall_cb": 0.375, "rouge_2_recall_ce": 0.375, "rouge_2_precision": 0.31579, "rouge_2_precision_cb": 0.31579, "rouge_2_precision_ce": 0.31579, "rouge_2_f_score": 0.34286, "rouge_2_f_score_cb": 0.34286, "rouge_2_f_score_ce": 0.34286, "rouge_3_recall": 0.26667, "rouge_3_recall_cb": 0.26667, "rouge_3_recall_ce": 0.26667, "rouge_3_precision": 0.22222, "rouge_3_precision_cb": 0.22222, "rouge_3_precision_ce": 0.22222, "rouge_3_f_score": 0.24242, "rouge_3_f_score_cb": 0.24242, "rouge_3_f_score_ce": 0.24242, "rouge_4_recall": 0.21429, "rouge_4_recall_cb": 0.21429, "rouge_4_recall_ce": 0.21429, "rouge_4_precision": 0.17647, "rouge_4_precision_cb": 0.17647, "rouge_4_precision_ce": 0.17647, "rouge_4_f_score": 0.19355, "rouge_4_f_score_cb": 0.19355, "rouge_4_f_score_ce": 0.19355, "rouge_l_recall": 0.47059, "rouge_l_recall_cb": 0.47059, "rouge_l_recall_ce": 0.47059, "rouge_l_precision": 0.4, "rouge_l_precision_cb": 0.4, "rouge_l_precision_ce": 0.4, "rouge_l_f_score": 0.43243, "rouge_l_f_score_cb": 0.43243, "rouge_l_f_score_ce": 0.43243, "rouge_w_1.2_recall": 0.24402, "rouge_w_1.2_recall_cb": 0.24402, "rouge_w_1.2_recall_ce": 0.24402, "rouge_w_1.2_precision": 0.36554, "rouge_w_1.2_precision_cb": 0.36554, "rouge_w_1.2_precision_ce": 0.36554, "rouge_w_1.2_f_score": 0.29267, "rouge_w_1.2_f_score_cb": 0.29267, "rouge_w_1.2_f_score_ce": 0.29267, "rouge_s*_recall": 0.20588, "rouge_s*_recall_cb": 0.20588, "rouge_s*_recall_ce": 0.20588, "rouge_s*_precision": 0.14737, "rouge_s*_precision_cb": 0.14737, "rouge_s*_precision_ce": 0.14737, "rouge_s*_f_score": 0.17178, "rouge_s*_f_score_cb": 0.17178, "rouge_s*_f_score_ce": 0.17178, "rouge_su*_recall": 0.23026, "rouge_su*_recall_cb": 0.23026, "rouge_su*_recall_ce": 0.23026, "rouge_su*_precision": 0.16746, "rouge_su*_precision_cb": 0.16746, "rouge_su*_precision_ce": 0.16746, "rouge_su*_f_score": 0.1939, "rouge_su*_f_score_cb": 0.1939, "rouge_su*_f_score_ce": 0.1939}, "TranS2S_bleu": 24.648321974767605, "TranS2S_meteor": 0.2311912252566519}