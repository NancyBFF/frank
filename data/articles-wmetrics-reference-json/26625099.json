{"BERTS2S": "a british man and his wife have won one of the world\\'s most successful men\\'s athletics championships.", "BERTS2S_lines": ["a british man and his wife have won one of the world\\'s most successful men\\'s athletics championships."], "TConvS2S": "the wife of one of the world\\'s most famous competitors athletes has said she is ``shocked\\'\\'by the lack of success in the sport.", "TConvS2S_lines": ["the wife of one of the world\\'s most famous competitors athletes has said she is ``shocked\\'\\'by the lack of success in the sport."], "Gold": "the uk wife carrying championships have a winner!", "Gold_lines": ["the uk wife carrying championships have a winner!"], "PtGen": "the world\\'s elephants have been celebrating the world\\'s elephants race, which has been at the centre of the world\\'s olympic games.", "PtGen_lines": ["the world\\'s elephants have been celebrating the world\\'s elephants race, which has been at the centre of the world\\'s olympic games."], "TranS2S": "a pair of paralympian pistols has set up a marathon on track in a bid to break the world championships in lithuania.", "TranS2S_lines": ["a pair of paralympian pistols has set up a marathon on track in a bid to break the world championships in lithuania."], "article": "18 March 2014 Last updated at 09:22 GMTRichard Blake-Smith and his partner Anna beat Vytautas Kirkliauskas of Lithuania, carrying his wife, Neringa Kirliauskiene.Rich said: \"We put in a whole week's work, running around the athletics track near where we live - and it's paid off\"\"We were pushed hard, especially by the Lithuanians there.\"Competitors must tackle a 380-metre course, hurdling over haystacks, scrabbling up a steep slope, and dodging water pistols.You don't need to be married to take part.The race saw all combinations of competitors - men carrying women, men carrying men and one woman carrying a woman.Rich and Anna will now compete at the World Championships in Finland in July.", "article_lines": ["18 March 2014", "Last updated at 09:22 GMTRichard Blake-Smith and his partner Anna beat Vytautas Kirkliauskas of Lithuania, carrying his wife, Neringa Kirliauskiene.", "Rich said: \"We put in a whole week's work, running around the athletics track near where we live - and it's paid", "off\"\"We were pushed hard, especially by the Lithuanians there.", "\"Competitors must tackle a 380-metre course, hurdling over haystacks, scrabbling up a steep slope, and dodging water pistols.", "You don't need to be married to take part.", "The race saw all combinations of competitors - men carrying women, men carrying men and one woman carrying a woman.", "Rich and Anna will now compete at the World Championships in Finland in July."], "entity_counter": {"Last": 1, "his partner": 1, "Anna": 2, "Vytautas Kirkliauskas": 1, "Lithuania": 1, "his wife": 1, "Neringa Kirliauskiene": 1, "a whole week's work": 1, "off\"\"We": 1, "the Lithuanians": 1, "a 380-metre course": 1, "haystacks": 1, "a steep slope": 1, "water pistols": 1, "part": 1, "The race": 1, "all combinations": 1, "competitors - men": 1, "women": 1, "men": 1, "a woman": 1, "the World Championships": 1, "Finland": 1}, "negative_entity": "Olympics", "url": "http://web.archive.org/web/20170428181258/http://www.bbc.co.uk/newsround/26625099", "hash": "26625099", "traps": [["F5", "we to 's put vytautas the rich paid at the championships."], ["F0", "18 march 2014"], ["F1", "rich and anna will not now compete at the world championships in finland in july ."], ["F5", "live a and pushed now."], ["F5", "men at course you put carrying must near a."], ["F0", "18 march 2014"]], "model_names": ["BERTS2S_lines", "TConvS2S_lines", "Gold_lines", "PtGen_lines", "TranS2S_lines"], "BERTS2S_rouge": {"rouge_1_recall": 0.625, "rouge_1_recall_cb": 0.625, "rouge_1_recall_ce": 0.625, "rouge_1_precision": 0.26316, "rouge_1_precision_cb": 0.26316, "rouge_1_precision_ce": 0.26316, "rouge_1_f_score": 0.37037, "rouge_1_f_score_cb": 0.37037, "rouge_1_f_score_ce": 0.37037, "rouge_2_recall": 0.0, "rouge_2_recall_cb": 0.0, "rouge_2_recall_ce": 0.0, "rouge_2_precision": 0.0, "rouge_2_precision_cb": 0.0, "rouge_2_precision_ce": 0.0, "rouge_2_f_score": 0.0, "rouge_2_f_score_cb": 0.0, "rouge_2_f_score_ce": 0.0, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.25, "rouge_l_recall_cb": 0.25, "rouge_l_recall_ce": 0.25, "rouge_l_precision": 0.10526, "rouge_l_precision_cb": 0.10526, "rouge_l_precision_ce": 0.10526, "rouge_l_f_score": 0.14815, "rouge_l_f_score_cb": 0.14815, "rouge_l_f_score_ce": 0.14815, "rouge_w_1.2_recall": 0.14694, "rouge_w_1.2_recall_cb": 0.14694, "rouge_w_1.2_recall_ce": 0.14694, "rouge_w_1.2_precision": 0.09378, "rouge_w_1.2_precision_cb": 0.09378, "rouge_w_1.2_precision_ce": 0.09378, "rouge_w_1.2_f_score": 0.11449, "rouge_w_1.2_f_score_cb": 0.11449, "rouge_w_1.2_f_score_ce": 0.11449, "rouge_s*_recall": 0.10714, "rouge_s*_recall_cb": 0.10714, "rouge_s*_recall_ce": 0.10714, "rouge_s*_precision": 0.01754, "rouge_s*_precision_cb": 0.01754, "rouge_s*_precision_ce": 0.01754, "rouge_s*_f_score": 0.03014, "rouge_s*_f_score_cb": 0.03014, "rouge_s*_f_score_ce": 0.03014, "rouge_su*_recall": 0.2, "rouge_su*_recall_cb": 0.2, "rouge_su*_recall_ce": 0.2, "rouge_su*_precision": 0.03704, "rouge_su*_precision_cb": 0.03704, "rouge_su*_precision_ce": 0.03704, "rouge_su*_f_score": 0.0625, "rouge_su*_f_score_cb": 0.0625, "rouge_su*_f_score_ce": 0.0625}, "BERTS2S_bleu": 2.5828020030551087, "BERTS2S_meteor": 0.17245508982035931, "TConvS2S_rouge": {"rouge_1_recall": 0.25, "rouge_1_recall_cb": 0.25, "rouge_1_recall_ce": 0.25, "rouge_1_precision": 0.08, "rouge_1_precision_cb": 0.08, "rouge_1_precision_ce": 0.08, "rouge_1_f_score": 0.12121, "rouge_1_f_score_cb": 0.12121, "rouge_1_f_score_ce": 0.12121, "rouge_2_recall": 0.0, "rouge_2_recall_cb": 0.0, "rouge_2_recall_ce": 0.0, "rouge_2_precision": 0.0, "rouge_2_precision_cb": 0.0, "rouge_2_precision_ce": 0.0, "rouge_2_f_score": 0.0, "rouge_2_f_score_cb": 0.0, "rouge_2_f_score_ce": 0.0, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.25, "rouge_l_recall_cb": 0.25, "rouge_l_recall_ce": 0.25, "rouge_l_precision": 0.08, "rouge_l_precision_cb": 0.08, "rouge_l_precision_ce": 0.08, "rouge_l_f_score": 0.12121, "rouge_l_f_score_cb": 0.12121, "rouge_l_f_score_ce": 0.12121, "rouge_w_1.2_recall": 0.14694, "rouge_w_1.2_recall_cb": 0.14694, "rouge_w_1.2_recall_ce": 0.14694, "rouge_w_1.2_precision": 0.07127, "rouge_w_1.2_precision_cb": 0.07127, "rouge_w_1.2_precision_ce": 0.07127, "rouge_w_1.2_f_score": 0.09598, "rouge_w_1.2_f_score_cb": 0.09598, "rouge_w_1.2_f_score_ce": 0.09598, "rouge_s*_recall": 0.03571, "rouge_s*_recall_cb": 0.03571, "rouge_s*_recall_ce": 0.03571, "rouge_s*_precision": 0.00333, "rouge_s*_precision_cb": 0.00333, "rouge_s*_precision_ce": 0.00333, "rouge_s*_f_score": 0.00609, "rouge_s*_f_score_cb": 0.00609, "rouge_s*_f_score_ce": 0.00609, "rouge_su*_recall": 0.08571, "rouge_su*_recall_cb": 0.08571, "rouge_su*_recall_ce": 0.08571, "rouge_su*_precision": 0.00926, "rouge_su*_precision_cb": 0.00926, "rouge_su*_precision_ce": 0.00926, "rouge_su*_f_score": 0.01671, "rouge_su*_f_score_cb": 0.01671, "rouge_su*_f_score_ce": 0.01671}, "TConvS2S_bleu": 1.3794462224541233, "TConvS2S_meteor": 0.09588014981273409, "PtGen_rouge": {"rouge_1_recall": 0.25, "rouge_1_recall_cb": 0.25, "rouge_1_recall_ce": 0.25, "rouge_1_precision": 0.08333, "rouge_1_precision_cb": 0.08333, "rouge_1_precision_ce": 0.08333, "rouge_1_f_score": 0.125, "rouge_1_f_score_cb": 0.125, "rouge_1_f_score_ce": 0.125, "rouge_2_recall": 0.0, "rouge_2_recall_cb": 0.0, "rouge_2_recall_ce": 0.0, "rouge_2_precision": 0.0, "rouge_2_precision_cb": 0.0, "rouge_2_precision_ce": 0.0, "rouge_2_f_score": 0.0, "rouge_2_f_score_cb": 0.0, "rouge_2_f_score_ce": 0.0, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.25, "rouge_l_recall_cb": 0.25, "rouge_l_recall_ce": 0.25, "rouge_l_precision": 0.08333, "rouge_l_precision_cb": 0.08333, "rouge_l_precision_ce": 0.08333, "rouge_l_f_score": 0.125, "rouge_l_f_score_cb": 0.125, "rouge_l_f_score_ce": 0.125, "rouge_w_1.2_recall": 0.14694, "rouge_w_1.2_recall_cb": 0.14694, "rouge_w_1.2_recall_ce": 0.14694, "rouge_w_1.2_precision": 0.07424, "rouge_w_1.2_precision_cb": 0.07424, "rouge_w_1.2_precision_ce": 0.07424, "rouge_w_1.2_f_score": 0.09864, "rouge_w_1.2_f_score_cb": 0.09864, "rouge_w_1.2_f_score_ce": 0.09864, "rouge_s*_recall": 0.03571, "rouge_s*_recall_cb": 0.03571, "rouge_s*_recall_ce": 0.03571, "rouge_s*_precision": 0.00362, "rouge_s*_precision_cb": 0.00362, "rouge_s*_precision_ce": 0.00362, "rouge_s*_f_score": 0.00657, "rouge_s*_f_score_cb": 0.00657, "rouge_s*_f_score_ce": 0.00657, "rouge_su*_recall": 0.08571, "rouge_su*_recall_cb": 0.08571, "rouge_su*_recall_ce": 0.08571, "rouge_su*_precision": 0.01003, "rouge_su*_precision_cb": 0.01003, "rouge_su*_precision_ce": 0.01003, "rouge_su*_f_score": 0.01796, "rouge_su*_f_score_cb": 0.01796, "rouge_su*_f_score_ce": 0.01796}, "PtGen_bleu": 1.5301683686839007, "PtGen_meteor": 0.03013182674199623, "TranS2S_rouge": {"rouge_1_recall": 0.375, "rouge_1_recall_cb": 0.375, "rouge_1_recall_ce": 0.375, "rouge_1_precision": 0.13636, "rouge_1_precision_cb": 0.13636, "rouge_1_precision_ce": 0.13636, "rouge_1_f_score": 0.2, "rouge_1_f_score_cb": 0.2, "rouge_1_f_score_ce": 0.2, "rouge_2_recall": 0.0, "rouge_2_recall_cb": 0.0, "rouge_2_recall_ce": 0.0, "rouge_2_precision": 0.0, "rouge_2_precision_cb": 0.0, "rouge_2_precision_ce": 0.0, "rouge_2_f_score": 0.0, "rouge_2_f_score_cb": 0.0, "rouge_2_f_score_ce": 0.0, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.25, "rouge_l_recall_cb": 0.25, "rouge_l_recall_ce": 0.25, "rouge_l_precision": 0.09091, "rouge_l_precision_cb": 0.09091, "rouge_l_precision_ce": 0.09091, "rouge_l_f_score": 0.13333, "rouge_l_f_score_cb": 0.13333, "rouge_l_f_score_ce": 0.13333, "rouge_w_1.2_recall": 0.14694, "rouge_w_1.2_recall_cb": 0.14694, "rouge_w_1.2_recall_ce": 0.14694, "rouge_w_1.2_precision": 0.08099, "rouge_w_1.2_precision_cb": 0.08099, "rouge_w_1.2_precision_ce": 0.08099, "rouge_w_1.2_f_score": 0.10442, "rouge_w_1.2_f_score_cb": 0.10442, "rouge_w_1.2_f_score_ce": 0.10442, "rouge_s*_recall": 0.03571, "rouge_s*_recall_cb": 0.03571, "rouge_s*_recall_ce": 0.03571, "rouge_s*_precision": 0.00433, "rouge_s*_precision_cb": 0.00433, "rouge_s*_precision_ce": 0.00433, "rouge_s*_f_score": 0.00772, "rouge_s*_f_score_cb": 0.00772, "rouge_s*_f_score_ce": 0.00772, "rouge_su*_recall": 0.11429, "rouge_su*_recall_cb": 0.11429, "rouge_su*_recall_ce": 0.11429, "rouge_su*_precision": 0.01587, "rouge_su*_precision_cb": 0.01587, "rouge_su*_precision_ce": 0.01587, "rouge_su*_f_score": 0.02787, "rouge_su*_f_score_cb": 0.02787, "rouge_su*_f_score_ce": 0.02787}, "TranS2S_bleu": 2.1671320168371846, "TranS2S_meteor": 0.08130081300813008}