{"BERTS2S": "the uk independence party spent more than \u00a3100, 000 on campaigning during the general election, the electoral commission has said.", "BERTS2S_lines": ["the uk independence party spent more than \u00a3100, 000 on campaigning during the general election, the electoral commission has said."], "TConvS2S": "the liberal democrats have spent # figures on the conservatives \\'election campaign.", "TConvS2S_lines": ["the liberal democrats have spent # figures on the conservatives \\'election campaign."], "Gold": "the uk independence party spent almost as much as the conservatives at this year\\'s european elections-while the lib dems outspent labour, electoral commission figures show.", "Gold_lines": ["the uk independence party spent almost as much as the conservatives at this year\\'s european elections-while the lib dems outspent labour, electoral commission figures show."], "PtGen": "the conservatives have retained control of the green party in the wake of the 2009 vote in the european elections.", "PtGen_lines": ["the conservatives have retained control of the green party in the wake of the 2009 vote in the european elections."], "TranS2S": "the liberal democrats spent more than \u00a31bn in the first three months of the 2015 general election, official figures show.", "TranS2S_lines": ["the liberal democrats spent more than \u00a31bn in the first three months of the 2015 general election, official figures show."], "article": "UKIP, which won May's election, spent \u00a32,956,737, while the Tories' campaign expenditure was \u00a32,980,815,The Lib Dems spent \u00a31,580,575 and lost all but one of their MEPs - Labour, which came second, spent \u00a31,027,339.The figures cover the campaign period from 23 January to polling day, 22 May.UKIP's campaign spending works out at 68p for each of their 4,376,635 votes. For Labour it is 26p per vote, the Conservatives 79p and the Lib Dems, who lost 11 of their 12 MEPs, \u00a31.45. The Green Party, which came fourth, spent \u00a3534,249 on its campaign - 43p for each of its 1,255,573 votes.Including the SNP's \u00a3267,372, the six highest-spending parties spent a total of \u00a39,347,087 on campaigning, the Electoral Commission said.All but Labour spent more than they did during the 2009 European election campaign.", "article_lines": ["UKIP, which won May's election, spent \u00a32,956,737, while the Tories' campaign expenditure was \u00a3", "2,980,815,The", "Lib Dems spent \u00a31,580,575 and lost all but one of their MEPs - Labour, which came second, spent \u00a31,027,339.The figures cover the campaign period from 23 January to polling day, 22 May.", "UKIP's campaign spending works out at 68p for each of their 4,376,635 votes.", "For Labour it is 26p per vote, the Conservatives 79p and the Lib Dems, who lost 11 of their 12 MEPs, \u00a31.45.", "The Green Party, which came fourth, spent \u00a3534,249 on its campaign - 43p for each of its 1,255,573 votes.", "Including the SNP's \u00a3267,372, the six highest-spending parties spent a total of \u00a39,347,087 on campaigning, the Electoral Commission said.", "All but Labour spent more than they did during the 2009 European election campaign."], "entity_counter": {"UKIP": 1, "May's election": 1, "the Tories' campaign expenditure": 1, "2,980,815,The": 1, "Lib Dems": 1, "their MEPs - Labour": 1, "\u00a31,027,339.The figures": 1, "the campaign period": 1, "polling day": 1, "UKIP's campaign spending": 1, "68p": 1, "their 4,376,635 votes": 1, "Labour": 2, "26p": 1, "vote": 1, "the Conservatives 79p": 1, "the Lib Dems": 1, "their 12 MEPs": 1, "The Green Party": 1, "its 1,255,573 votes": 1, "the six highest-spending parties": 1, "a total": 1, "campaigning": 1, "the Electoral Commission": 1, "the 2009 European election campaign": 1}, "negative_entity": "influenza", "url": "http://web.archive.org/web/20150927034831/http://www.bbc.co.uk/news/uk-politics-30520122", "hash": "30520122", "traps": [["F5", "'s during campaign its ' spending which."], ["F5", "six snp campaign spent than all."], ["F4", "the 23-year-old from kinross finished second behind kenyan faith kipyegon in four minutes, 19.12 seconds."], ["F0", "ukip, which won may's election, spent \u00a32,956,737, while the tories' campaign expenditure was \u00a3"], ["F1", "ukip , which won may 's election , spent \u00a3 2,956,737 , while the tories ' campaign expenditure was not \u00a3"], ["F1", "ukip , which won may 's election , spent \u00a3 2,956,737 , while the tories ' campaign expenditure was not \u00a3"]], "model_names": ["BERTS2S_lines", "TConvS2S_lines", "Gold_lines", "PtGen_lines", "TranS2S_lines"], "BERTS2S_rouge": {"rouge_1_recall": 0.37037, "rouge_1_recall_cb": 0.37037, "rouge_1_recall_ce": 0.37037, "rouge_1_precision": 0.5, "rouge_1_precision_cb": 0.5, "rouge_1_precision_ce": 0.5, "rouge_1_f_score": 0.42553, "rouge_1_f_score_cb": 0.42553, "rouge_1_f_score_ce": 0.42553, "rouge_2_recall": 0.19231, "rouge_2_recall_cb": 0.19231, "rouge_2_recall_ce": 0.19231, "rouge_2_precision": 0.26316, "rouge_2_precision_cb": 0.26316, "rouge_2_precision_ce": 0.26316, "rouge_2_f_score": 0.22222, "rouge_2_f_score_cb": 0.22222, "rouge_2_f_score_ce": 0.22222, "rouge_3_recall": 0.12, "rouge_3_recall_cb": 0.12, "rouge_3_recall_ce": 0.12, "rouge_3_precision": 0.16667, "rouge_3_precision_cb": 0.16667, "rouge_3_precision_ce": 0.16667, "rouge_3_f_score": 0.13954, "rouge_3_f_score_cb": 0.13954, "rouge_3_f_score_ce": 0.13954, "rouge_4_recall": 0.08333, "rouge_4_recall_cb": 0.08333, "rouge_4_recall_ce": 0.08333, "rouge_4_precision": 0.11765, "rouge_4_precision_cb": 0.11765, "rouge_4_precision_ce": 0.11765, "rouge_4_f_score": 0.09756, "rouge_4_f_score_cb": 0.09756, "rouge_4_f_score_ce": 0.09756, "rouge_l_recall": 0.37037, "rouge_l_recall_cb": 0.37037, "rouge_l_recall_ce": 0.37037, "rouge_l_precision": 0.5, "rouge_l_precision_cb": 0.5, "rouge_l_precision_ce": 0.5, "rouge_l_f_score": 0.42553, "rouge_l_f_score_cb": 0.42553, "rouge_l_f_score_ce": 0.42553, "rouge_w_1.2_recall": 0.15401, "rouge_w_1.2_recall_cb": 0.15401, "rouge_w_1.2_recall_ce": 0.15401, "rouge_w_1.2_precision": 0.40193, "rouge_w_1.2_precision_cb": 0.40193, "rouge_w_1.2_precision_ce": 0.40193, "rouge_w_1.2_f_score": 0.22269, "rouge_w_1.2_f_score_cb": 0.22269, "rouge_w_1.2_f_score_ce": 0.22269, "rouge_s*_recall": 0.12821, "rouge_s*_recall_cb": 0.12821, "rouge_s*_recall_ce": 0.12821, "rouge_s*_precision": 0.23684, "rouge_s*_precision_cb": 0.23684, "rouge_s*_precision_ce": 0.23684, "rouge_s*_f_score": 0.16636, "rouge_s*_f_score_cb": 0.16636, "rouge_s*_f_score_ce": 0.16636, "rouge_su*_recall": 0.14589, "rouge_su*_recall_cb": 0.14589, "rouge_su*_recall_ce": 0.14589, "rouge_su*_precision": 0.26316, "rouge_su*_precision_cb": 0.26316, "rouge_su*_precision_ce": 0.26316, "rouge_su*_f_score": 0.18772, "rouge_su*_f_score_cb": 0.18772, "rouge_su*_f_score_ce": 0.18772}, "BERTS2S_bleu": 15.292705335458642, "BERTS2S_meteor": 0.17594166855845556, "TConvS2S_rouge": {"rouge_1_recall": 0.22222, "rouge_1_recall_cb": 0.22222, "rouge_1_recall_ce": 0.22222, "rouge_1_precision": 0.54545, "rouge_1_precision_cb": 0.54545, "rouge_1_precision_ce": 0.54545, "rouge_1_f_score": 0.31579, "rouge_1_f_score_cb": 0.31579, "rouge_1_f_score_ce": 0.31579, "rouge_2_recall": 0.03846, "rouge_2_recall_cb": 0.03846, "rouge_2_recall_ce": 0.03846, "rouge_2_precision": 0.1, "rouge_2_precision_cb": 0.1, "rouge_2_precision_ce": 0.1, "rouge_2_f_score": 0.05555, "rouge_2_f_score_cb": 0.05555, "rouge_2_f_score_ce": 0.05555, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.18519, "rouge_l_recall_cb": 0.18519, "rouge_l_recall_ce": 0.18519, "rouge_l_precision": 0.45455, "rouge_l_precision_cb": 0.45455, "rouge_l_precision_ce": 0.45455, "rouge_l_f_score": 0.26316, "rouge_l_f_score_cb": 0.26316, "rouge_l_f_score_ce": 0.26316, "rouge_w_1.2_recall": 0.07687, "rouge_w_1.2_recall_cb": 0.07687, "rouge_w_1.2_recall_ce": 0.07687, "rouge_w_1.2_precision": 0.36475, "rouge_w_1.2_precision_cb": 0.36475, "rouge_w_1.2_precision_ce": 0.36475, "rouge_w_1.2_f_score": 0.12698, "rouge_w_1.2_f_score_cb": 0.12698, "rouge_w_1.2_f_score_ce": 0.12698, "rouge_s*_recall": 0.03419, "rouge_s*_recall_cb": 0.03419, "rouge_s*_recall_ce": 0.03419, "rouge_s*_precision": 0.21818, "rouge_s*_precision_cb": 0.21818, "rouge_s*_precision_ce": 0.21818, "rouge_s*_f_score": 0.05912, "rouge_s*_f_score_cb": 0.05912, "rouge_s*_f_score_ce": 0.05912, "rouge_su*_recall": 0.04775, "rouge_su*_recall_cb": 0.04775, "rouge_su*_recall_ce": 0.04775, "rouge_su*_precision": 0.27692, "rouge_su*_precision_cb": 0.27692, "rouge_su*_precision_ce": 0.27692, "rouge_su*_f_score": 0.08145, "rouge_su*_f_score_cb": 0.08145, "rouge_su*_f_score_ce": 0.08145}, "TConvS2S_bleu": 2.6608792518605076, "TConvS2S_meteor": 0.12277654001727997, "PtGen_rouge": {"rouge_1_recall": 0.25926, "rouge_1_recall_cb": 0.25926, "rouge_1_recall_ce": 0.25926, "rouge_1_precision": 0.35, "rouge_1_precision_cb": 0.35, "rouge_1_precision_ce": 0.35, "rouge_1_f_score": 0.29787, "rouge_1_f_score_cb": 0.29787, "rouge_1_f_score_ce": 0.29787, "rouge_2_recall": 0.07692, "rouge_2_recall_cb": 0.07692, "rouge_2_recall_ce": 0.07692, "rouge_2_precision": 0.10526, "rouge_2_precision_cb": 0.10526, "rouge_2_precision_ce": 0.10526, "rouge_2_f_score": 0.08889, "rouge_2_f_score_cb": 0.08889, "rouge_2_f_score_ce": 0.08889, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.18519, "rouge_l_recall_cb": 0.18519, "rouge_l_recall_ce": 0.18519, "rouge_l_precision": 0.25, "rouge_l_precision_cb": 0.25, "rouge_l_precision_ce": 0.25, "rouge_l_f_score": 0.21277, "rouge_l_f_score_cb": 0.21277, "rouge_l_f_score_ce": 0.21277, "rouge_w_1.2_recall": 0.07687, "rouge_w_1.2_recall_cb": 0.07687, "rouge_w_1.2_recall_ce": 0.07687, "rouge_w_1.2_precision": 0.20061, "rouge_w_1.2_precision_cb": 0.20061, "rouge_w_1.2_precision_ce": 0.20061, "rouge_w_1.2_f_score": 0.11115, "rouge_w_1.2_f_score_cb": 0.11115, "rouge_w_1.2_f_score_ce": 0.11115, "rouge_s*_recall": 0.04843, "rouge_s*_recall_cb": 0.04843, "rouge_s*_recall_ce": 0.04843, "rouge_s*_precision": 0.08947, "rouge_s*_precision_cb": 0.08947, "rouge_s*_precision_ce": 0.08947, "rouge_s*_f_score": 0.06284, "rouge_s*_f_score_cb": 0.06284, "rouge_s*_f_score_ce": 0.06284, "rouge_su*_recall": 0.06101, "rouge_su*_recall_cb": 0.06101, "rouge_su*_recall_ce": 0.06101, "rouge_su*_precision": 0.11005, "rouge_su*_precision_cb": 0.11005, "rouge_su*_precision_ce": 0.11005, "rouge_su*_f_score": 0.0785, "rouge_su*_f_score_cb": 0.0785, "rouge_su*_f_score_ce": 0.0785}, "PtGen_bleu": 3.394201704566131, "PtGen_meteor": 0.10704876375877997, "TranS2S_rouge": {"rouge_1_recall": 0.25926, "rouge_1_recall_cb": 0.25926, "rouge_1_recall_ce": 0.25926, "rouge_1_precision": 0.35, "rouge_1_precision_cb": 0.35, "rouge_1_precision_ce": 0.35, "rouge_1_f_score": 0.29787, "rouge_1_f_score_cb": 0.29787, "rouge_1_f_score_ce": 0.29787, "rouge_2_recall": 0.03846, "rouge_2_recall_cb": 0.03846, "rouge_2_recall_ce": 0.03846, "rouge_2_precision": 0.05263, "rouge_2_precision_cb": 0.05263, "rouge_2_precision_ce": 0.05263, "rouge_2_f_score": 0.04444, "rouge_2_f_score_cb": 0.04444, "rouge_2_f_score_ce": 0.04444, "rouge_3_recall": 0.0, "rouge_3_recall_cb": 0.0, "rouge_3_recall_ce": 0.0, "rouge_3_precision": 0.0, "rouge_3_precision_cb": 0.0, "rouge_3_precision_ce": 0.0, "rouge_3_f_score": 0.0, "rouge_3_f_score_cb": 0.0, "rouge_3_f_score_ce": 0.0, "rouge_4_recall": 0.0, "rouge_4_recall_cb": 0.0, "rouge_4_recall_ce": 0.0, "rouge_4_precision": 0.0, "rouge_4_precision_cb": 0.0, "rouge_4_precision_ce": 0.0, "rouge_4_f_score": 0.0, "rouge_4_f_score_cb": 0.0, "rouge_4_f_score_ce": 0.0, "rouge_l_recall": 0.22222, "rouge_l_recall_cb": 0.22222, "rouge_l_recall_ce": 0.22222, "rouge_l_precision": 0.3, "rouge_l_precision_cb": 0.3, "rouge_l_precision_ce": 0.3, "rouge_l_f_score": 0.25532, "rouge_l_f_score_cb": 0.25532, "rouge_l_f_score_ce": 0.25532, "rouge_w_1.2_recall": 0.08878, "rouge_w_1.2_recall_cb": 0.08878, "rouge_w_1.2_recall_ce": 0.08878, "rouge_w_1.2_precision": 0.23171, "rouge_w_1.2_precision_cb": 0.23171, "rouge_w_1.2_precision_ce": 0.23171, "rouge_w_1.2_f_score": 0.12837, "rouge_w_1.2_f_score_cb": 0.12837, "rouge_w_1.2_f_score_ce": 0.12837, "rouge_s*_recall": 0.05698, "rouge_s*_recall_cb": 0.05698, "rouge_s*_recall_ce": 0.05698, "rouge_s*_precision": 0.10526, "rouge_s*_precision_cb": 0.10526, "rouge_s*_precision_ce": 0.10526, "rouge_s*_f_score": 0.07394, "rouge_s*_f_score_cb": 0.07394, "rouge_s*_f_score_ce": 0.07394, "rouge_su*_recall": 0.06897, "rouge_su*_recall_cb": 0.06897, "rouge_su*_recall_ce": 0.06897, "rouge_su*_precision": 0.1244, "rouge_su*_precision_cb": 0.1244, "rouge_su*_precision_ce": 0.1244, "rouge_su*_f_score": 0.08874, "rouge_su*_f_score_cb": 0.08874, "rouge_su*_f_score_ce": 0.08874}, "TranS2S_bleu": 5.976975777859543, "TranS2S_meteor": 0.1054690609126265}